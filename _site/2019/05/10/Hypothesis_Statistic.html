<!DOCTYPE html>
<html>

<head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#">
<meta charset="utf-8" />
<meta http-equiv='X-UA-Compatible' content='IE=edge'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>
<title>Khoa học dữ liệu</title>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
<!-- Style for main home page -->
<link rel="stylesheet" href="/assets/css/styles.css">
<link rel="stylesheet" href="/assets/css/styles_toc.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
<script data-ad-client="ca-pub-4263248182804679" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> 
<link href="https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300" rel="stylesheet">
<!-- <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet"> -->
<link href="https://fonts.googleapis.com/css?family=Roboto|Source+Sans+Pro" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Fira+Sans" rel="stylesheet">
<link rel="icon" type="image/jpg" href="assets/images/logo.jpg" sizes="32x32">
<link rel="canonical" href="https://phamdinhkhanh.github.io"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="author" content="Phạm Đình Khánh" />
<meta property="og:title" content="" />
<meta property="og:site_name" content="Khanh's blog" />
<meta property="og:url" content="https://phamdinhkhanh.github.io" />
<meta property="og:description" content="" />

<meta property="og:type" content="article" />
<meta property="article:published_time" content="" />


<meta property="article:author" content="Khanh" />
<meta property="article:section" content="" />

<link rel="alternate" type="application/atom+xml" title="Khanh's blog - Atom feed" href="/feed.xml" />
<style>
	
</style>
<!-- -- Import latext  -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
	skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
	inlineMath: [['$','$']]
  }
});
</script>

<!-- Google Analytics -->

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-89509207-1', 'auto');
// ga('send', 'pageview');
ga('send', 'pageview', {
'page': '/',
'title': ''
});
</script>


<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-KTCD8BX');</script>
<!-- End Google Tag Manager -->
</head>
<style>
body {
  padding: 0 7.5%;
}
</style>

<body>
	<div id="fb-root"></div>
	<!-- <script>(function(d, s, id) { -->
	  <!-- var js, fjs = d.getElementsByTagName(s)[0]; -->
	  <!-- if (d.getElementById(id)) return; -->
	  <!-- js = d.createElement(s); js.id = id; -->
	  <!-- js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.9"; -->
	  <!-- fjs.parentNode.insertBefore(js, fjs); -->
	<!-- }(document, 'script', 'facebook-jssdk'));</script> -->
	<br>
	<div content = "container">
		<div class="row">
			<div class="col-md-2 hidden-xs hidden-sm">
				<a  href="/">
					<img width="100%" style="padding-bottom: 3mm;" src="/assets/images/img.jpg" /> </a>
				<br>
				<nav>
					<div class="header">Latest</div>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/05/23/BERTModel.html">Bài 36 - BERT model</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/05/05/MultitaskLearning_MultiBranch.html">Bài 35 - Multitask Learning - Multi Branch</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/04/22/MultitaskLearning.html">Bài 34 - Multitask Learning</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/04/15/TransferLearning.html">Bài 33 - Phương pháp Transfer Learning</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/04/09/TensorflowDataset.html">Bài 32 - Kĩ thuật tensorflow Dataset</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/04/03/AWS.html">Bài 31 - Amazon Virtual Machine Deep Learning</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/28/deployTensorflowJS.html">Bài 30 - Xây dựng Web AI trên tensorflow js</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/23/FlaskRestAPI.html">Bài 29 - Xây dựng Flask API cho mô hình deep learning</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/21/faceNet.html">Bài 28 - Thực hành training Facenet</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/12/faceNetAlgorithm.html">Bài 27 - Mô hình Facenet trong face recognition</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/10/DarknetGoogleColab.html">Bài 26 - Huấn luyện YOLO darknet trên google colab</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/09/DarknetAlgorithm.html">Bài 25 - YOLO You Only Look Once</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/02/17/ImbalancedData.html">Bài 24 - Mất cân bằng dữ liệu (imbalanced dataset)</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/02/11/NARSyscom2015.html">Bài 23 - Neural Attentive Session-Based Recommendation</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/01/17/ScoreCard.html">Bài 22 - Scorecard model</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/01/06/ImagePreprocessing.html">Bài 21 - Tiền xử lý ảnh OpenCV</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/12/26/Sorfmax_Recommendation_Neural_Network.html">Bài 20 - Recommendation Neural Network</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/12/12/ARIMAmodel.html">Bài 19 - Mô hình ARIMA trong time series</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/12/02/DeepLearningLayer.html">Bài 18 - Các layers quan trọng trong deep learning</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/11/22/HOG.html">Bài 17 - Thuật toán HOG (Histrogram of oriented gradient)</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/11/08/RFMModel.html">Bài 16 - Model RFM phân khúc khách hàng</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/11/04/Recommendation_Compound_Part1.html">Bài 15 - collaborative và content-based filtering</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/10/22/googleHeatmap.html">Bài 14 - Biểu đồ trên Google Map</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/10/05/SSDModelObjectDetection.html">Bài 13 - Model SSD trong Object Detection</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/09/29/OverviewObjectDetection.html">Bài 12 - Các thuật toán Object Detection</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/09/16/VisualizationPython.html">Bài 11 - Visualization trong python</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/09/08/LDATopicModel.html">Bài 10 - Thuật toán LDA - Xác định Topic</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/08/25/PyTorch_Torchtext_Tutorial.html">Bài 9 - Pytorch - Buổi 3 - torchtext module NLP</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/08/19/CorrectSpellingVietnamseTonePrediction.html">Bài 7 - Pytorch - Buổi 2 - Seq2seq model correct spelling</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/08/10/PytorchTurtorial1.html">Bài 6 - Pytorch - Buổi 1 - Làm quen với pytorch</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/07/15/PySparkSQL.html">Bài 5 - Model Pipeline - SparkSQL</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/06/18/AttentionLayer.html">Bài 4 -  Attention is all you need</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/05/10/Hypothesis_Statistic.html">Apenddix 1 - Lý thuyết phân phối và kiểm định thống kê</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/04/29/ModelWord2Vec.html">Bài 3 - Mô hình Word2Vec</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/04/22/Ly_thuyet_ve_mang_LSTM.html">Bài 2 - Lý thuyết về mạng LSTM part 2</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/01/07/Ky_thuat_feature_engineering.html">Bài 1 - Kĩ thuật feature engineering</a></li>
					
				</nav>
			</div>
			<div class="col-md-8 col-xs-12" style="z-index:1">
				<nav class="navbar navbar-inverse" style="background-color: #046897">
					<div class = "container-fluid">
						<div class = "navbar-header>
							<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
								<span class="icon-bar"></span>
								<span class="icon-bar"></span>
								<span class="icon-bar"></span>
							</button>
							<a class="navbar-brand" href="/">
								<span style="color:#FFF">Khoa học dữ liệu - Khanh's blog</span>
							</a>
						</div>
						<br>
						<br>
						<div class="collapse navbar-collapse navbar-right" id="myNavbar">
							<ul class="nav navbar-nav">
								<li><a href="/home"><span style="color: #fff"> Home</span></a></li>
								<li><a href="/about"><span style="color: #fff"> About</span></a></li>
								<!-- <li><a href="/da"><span style="color: #fff">Data Analytics</span></a></li> -->
								<!-- <li><a href="/cv"><span style="color: #fff">Computer Vision</span></a></li> -->
								<!-- <li><a href="/nlp"><span style="color: #fff">NLP</span></a></li> -->
								<!-- <li><a href="/code"><span style="color: #fff">Code</span></a></li> -->
								<li><a href="/book"><span style="color: #fff">Book</span></a></li>
							</ul>
						</div>
					</div>
				</nav>
				<div class="PageNavigation">
				</div>
				<h1 itemprop="name" class="post-title"></h1>
				<div id="bootstrap-overrides">
					<div>
<h2><p class="post-link" style="text-align: left; color: #204081; font-weight: bold">Apenddix 1 - Lý thuyết phân phối và kiểm định thống kê</p></h2> 
<strong>10 May 2019 - phamdinhkhanh</strong>
</div>
<br/>
<div id="toc"></div>
<h1 id="phần-1---thống-kê">Phần 1 - Thống kê</h1>

<h2 id="11-các-đại-lượng-thống-kê">1.1. Các đại lượng thống kê</h2>

<p>1.<strong>Đại lượng ngẫu nhiên</strong>: Một đại lượng được coi là ngẫu nhiên nếu giá trị của nó là kết quả của một biến cố ngẫu nhiên. Chẳng hạn phép tung đồng xu đồng chất với 2 mặt xấp ngửa là một đại lượng ngẫu nhiên vì ta không hoàn toàn biết trước khả năng đồng xu rơi vào mặt xấp hoặc ngửa. Có 2 loại đại lượng ngẫu nhiên:</p>
<ul>
  <li>Đại lượng ngẫu nhiên liên tục: Giá trị của nó có thể rơi vào bất kì một giá trị nào nằm trong một khoảng xác định. Chẳng hạn chiều cao, cân nặng của một người có thể coi là đại lượng liên tục.</li>
  <li>Đại lượng ngẫu nhiên rời rạc: Giá trị của nó nằm trong một tập hợp hữu hạn các khả năng. Ví dụ như trường hợp tung đồng xu ta chỉ có thể nhận các giá trị là {0, 1} tương ứng với khả năng rơi vào mặt S(sấp) hặc mặt N (ngửa).</li>
</ul>

<p>2.<strong>Kì vọng</strong>: là giá trị trung bình của một đại lượng ngẫu nhiên. Giá trị của kỳ vọng được chia thành 2 trường hợp:</p>

<ul>
  <li>
    <p>Nếu $\text{x}$ là đại lượng ngẫu nhiên rời rạc.</p>

    <script type="math/tex; mode=display">\text{E(x)} = \bar{\text{x}} = \sum_{i=1}^{n} x_i p(x_i)</script>

    <p>Trong đó $p(x_i)$ là xác xuất xảy ra biến cố $x = x_i$. Khi khả năng xảy ra của các biến cố ngẫu nhiên rời rạc $x_i$ là như nhau thì giá trị của kỳ vọng: $\text{E}(x) = \frac{\sum_{i=1}^{n}x_i}{n}$</p>
  </li>
  <li>
    <p>Nếu $\text{x}$ là một đại lượng ngẫu nhiên liên tục:</p>

    <script type="math/tex; mode=display">\text{E(x) }= \bar{\text{x}} = \int xp(x) dx</script>

    <p>Một số tính chất của kì vọng:</p>
    <ul>
      <li>$\text{E(ax)} = a\text{E(x)}$</li>
      <li>$\text{E(ax+by)} = a\text{E(x)} + b\text{E(y)}$</li>
      <li>Nếu $\text{x, y}$ là 2 biến ngẫu nhiên độc lập thì $\text{E(xy)} = \text{E(x)}\text{E(y)}$</li>
    </ul>
  </li>
</ul>

<p>3.<strong>Hiệp phương sai</strong>: Là đại lượng đo lường mối quan hệ cùng chiều hoặc ngược chiều giữa 2 biến ngẫu nhiên. Đây là đại lượng được sử dụng nhiều trong kinh tế lượng và thống kê học để giải thích mối quan hệ tác động giữa các biến. Khi hiệp phương sai giữa 2 biến lớn hơn 0, chúng có quan hệ đồng biến và ngược lại. Hiệp phương sai chỉ được tính trên 2 chuỗi có cùng độ dài.</p>

<script type="math/tex; mode=display">\text{cov(x, y)} = \text{E}[(\text{x}-\bar{\text{x}})(\text{y}-\bar{\text{y}})] = \frac{\sum_{i=1}^{n} (x_i-\bar{\text{x}})(y_i-\bar{\text{y}})}{n}</script>

<p>Gía trị của hiệp phương sai giữa 2 chuỗi số $\text{x,y}$ được kí hiệu là $\text{cov(x,y)}$ hoặc $\sigma_{\text{xy}}$ và được tính bằng kì vọng của tích chéo độ lệch so với trung bình của 2 đại lượng như công thức trên.</p>

<p>Như vậy ta có thể rút ra các tính chất của hiệp phương sai:</p>
<ul>
  <li>tính chất giao hoán: 
<script type="math/tex">\text{cov(x, y) = cov(y, x)}</script></li>
  <li>tính chất tuyến tính:
<script type="math/tex">\text{cov(ax, by) = ab.cov(x, y)}</script></li>
  <li>Khai triển công thức hiệp phương sai ta có:
<script type="math/tex">% <![CDATA[
\begin{eqnarray}\text{cov(x, y)} & = & \text{E(xy)}-\mu_\text{x}\text{E(y)}-\mu_\text{y}\text{E(x)} + \mu_\text{x}\mu_\text{y}\end{eqnarray} %]]></script></li>
</ul>

<p>Trong đó $\mu_\text{x}, \mu_\text{y}$ lần lượt là kì vọng của $\text{x, y}$. Chứng minh công thức trên không khó. Xin dành cho bạn đọc.</p>

<p>4.<strong>Phương sai</strong>: Là trường hợp đặc biệt của hiệp phương sai giữa một đại lượng ngẫu nhiên với chính nó. Giá trị của phương sai luôn lớn hơn hoặc bằng 0 do bằng tổng bình phương sai số của từng mẫu so với kỳ vọng. Trong trường hợp phương sai bằng 0, đại lượng là một hằng số không biến thiên. Phương sai của một đại lượng thể hiện mức độ biến động của đại lượng đó xung quanh giá trị kỳ vọng. Nếu phương sai càng lớn, miền biến thiên của đại lượng càng cao và ngược lại.</p>

<p>Phương sai được kí hiệu là $\text{Var}(x)$, $\sigma_x^2$ hoặc $s_x^2$. Công thức phương sai được tính như sau:</p>

<ul>
  <li>
    <p>Nếu $x$ là đại lượng ngẫu nhiên rời rạc:</p>

    <script type="math/tex; mode=display">\text{Var}(x) = \sum_{i=1}^{n} (x_i-\mu)^2 p(x_i) dx</script>

    <p>Trong đó $\text{E}(x) = \mu$. Khi các biến cố xảy ra với cùng xác xuất bằng $\frac{1}{n}$, phương sai chính là trung bình $\text{Var}(x) = \frac{\sum_{i=1}^{n} (x_i-\mu)^2}{n}$</p>
  </li>
  <li>
    <p>Nếu $x$ là đại lượng ngẫu nhiên liên tục:</p>

    <script type="math/tex; mode=display">\text{Var}(x) = \int (x-\mu)^2 p(x) dx</script>

    <p>Phương sai của một biến có thể được tính toán thông qua kì vọng của biến:</p>

    <script type="math/tex; mode=display">% <![CDATA[
\begin{eqnarray}\text{Var}(x) & = & \text{E}((x-\mu)^2) \\
  & = & \text{E}((x^2-2\mu x+\mu^2)) \\
  & = & \text{E}(x^2)-2\mu \text{E}(x)+\text{E}(\mu^2) \\
  & = & \text{E}(x^2)-2\mu^2+\mu^2 \\
  & = & \text{E}(x^2)-\mu^2 \\
  & = & \text{E}(x^2)-\text{E}(x)^2 \\
  \end{eqnarray} %]]></script>

    <p>Đây là một trong những tính chất rất thường được sử dụng trong tính toán nhanh phương sai mà bạn đọc cần nhớ. Đồng thời từ công thức trên ta cũng suy ra một bất đẳng thức quan trọng đó là kỳ vọng của bình phương luôn lớn hơn bình phương của kỳ vọng: $\text{E}(x^2) \geq \text{E}(x)^2$</p>
  </li>
</ul>

<p>5.<strong>Độ lệch chuẩn</strong>: Độ lệch chuẩn của một đại lượng có giá trị bằng căn bậc 2 của phương sai. Nó đại diện cho sai số của đại lượng so với trung bình.</p>

<script type="math/tex; mode=display">\sigma_x = \sqrt{\text{Var}(x)}</script>

<p>Trong trường hợp các biến rời rạc phân phối đều với xác xuất $\frac{1}{n}$:</p>

<script type="math/tex; mode=display">\sigma_x = \sqrt{\frac{\sum_{i=1}^{n}(x-\bar{x})^2}{n}}</script>

<p>Trong thống kê chúng ta thường xác định các giá trị outliers dựa trên nguyên lý 3 sigma bằng cách xem những giá trị nằm ngoài khoảng $[\mu-3\sigma, \mu+3\sigma]$ như là outliers. Ta có thể xử lý outliers bằng cách đưa về đầu mút gần nhất $\mu-3\sigma$ hoặc $\mu+3\sigma$ hoặc loại bỏ luôn outliers.</p>

<p>6.<strong>Hệ số tương quan</strong>: Là một chỉ số có quan hệ gần gũi với hiệp phương sai. Hệ số tương quan đánh giá mối quan hệ đồng biến hay nghịch biến giữa 2 đại lượng ngẫu nhiên. Tuy nhiên khác với hiệp phương sai, hệ số tương quan cho biết thêm mối quan hệ tương quan tuyến tính giữa 2 biến là mạnh hay yếu.</p>

<p>Hệ số tương quan giao động trong khoảng [-1, 1]. Tại 2 giá trị đầu mút -1 và 1, hai biến hoàn toàn tương quan tuyến tính. Tức ta có thể biểu diễn $\text{y}=a\text{x}+b$. Trường hợp hệ số tương quan bằng 0, hai đại lượng là độc lập tuyến tính. Phương trình biểu diễn tương quan được tính như sau:</p>

<script type="math/tex; mode=display">\rho_{\text{xy}} = \frac{\text{cov(x,y)}}{\sigma_{x}\sigma_{y}}</script>

<p>Trong hồi qui tuyến tính và logistic, hệ số tương quan thường được dùng để ranking mức độ quan trọng của biến trước khi thực hiện hồi qui. Trong các mô hình timeseries như ARIMA, GARCH chúng ta cũng xác định các tham số bậc tự do của phương trình hồi qui dựa trên hệ số tương quan giữa các chuỗi với độ trễ của nó.</p>

<h2 id="12-qui-luật-số-lớn">1.2. Qui luật số lớn</h2>

<p>Qui luật số lớn cho rằng khi một mẫu con có kích thước càng lớn được rút ra từ tổng thể thì trung bình của nó càng đại diện cho tổng thể. Phát biểu toán học của qui luật số lớn:</p>

<p>Xét $n$ mẫu ngẫu nhiên $X_1, X_2,…, X_n$ độc lập cùng tuân theo phân phối $\mathbf{N}(\mu, \sigma^2)$, với mọi số thực $\epsilon$  dương, xác suất để khoảng cách giữa trung bình tích lũy và kỳ vọng $P(\frac{X_{1}+X_{2}+…+X_{n}}{n} - \text{E(X)} &gt; 
\epsilon) \rightarrow 0$ khi $n \rightarrow \infty$ hay biểu diễn lim:</p>

<script type="math/tex; mode=display">\lim_{n \rightarrow \infty} P(|\frac {X_{1}+X_{2}+...+X_{n}}{n} - \text{E(X)}| \geq \epsilon) = 0</script>

<p>Để chứng minh định lý này ta cần sử dụng đến bất đẳng thức Markov: Xác xuất để một biến ngẫu nhiên $\text{X}$ không âm lớn hơn $a$ ($a &gt; 0$) luôn nhỏ hơn kì vọng của biến ngẫu nhiên đó chia cho $a$.
<script type="math/tex">P(\text{X}\geq a) \leq \frac{\text{E(X)}}{a}</script></p>

<p><strong>Chứng minh bất đẳng thức markov:</strong></p>

<p>Do $x$ không âm nên</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{eqnarray}\text{E(X)} &=& \int_{0}^{\infty} xf(x)dx \\
&=& \int_{0}^{a} xf(x)dx + \int_{a}^{\infty} xf(x)dx \\
&\geq& \int_{a}^{\infty} xf(x)dx \\
&\geq& \int_{a}^{\infty} af(x)dx \\
&=& a\int_{a}^{\infty}f(x)dx \\
&=& a.P(\text{X} \geq a)\end{eqnarray} %]]></script>

<p>Từ đó suy ra <script type="math/tex">P(\text{X}\geq a) \leq \frac{\text{E(X)}}{a}</script></p>

<p><strong>Chứng minh qui luật số lớn:</strong></p>

<script type="math/tex; mode=display">P(|\frac {X_{1}+X_{2}+...+X_{n}}{n} - \text{E(X)}| \geq \epsilon) = P((\frac {X_{1}+X_{2}+...+X_{n}}{n} - \text{E(X)})^2 \geq \epsilon^2)</script>

<p>Đặt $\text{Z} = (Y_{n}-\text{E(X)})^2$. Áp dụng bất đẳng thức markov cho đại lượng không âm $\text{Z}$, ta có:
<script type="math/tex">P(\text{Z} \geq \epsilon^2) \leq \frac{\text{E(Z)}}{\epsilon^2} \tag{1}</script>
Mặt khác khi $n$ tiến tới $\infty$:</p>

<script type="math/tex; mode=display">\text{E}(Y_n) = \text{E(X)}</script>

<p>Ở đây ta coi $X_1, X_2, \dots, X_n$ là các biến độc lập. Khi đó:</p>

<script type="math/tex; mode=display">\text{Var}(Y_{n}) = \text{Var}(\frac{X_1 + X_2 + \dots + X_n}{n}) = \frac{n\text{Var(X)}}{n^2} = \frac{\text{Var(X)}}{n}</script>

<p>Do đó:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{eqnarray}\lim_{n \rightarrow \infty}\text{E(Z)} & = & \lim_{n \rightarrow \infty}\text{E}(Y_{n}-\text{E(X)})^2 \\
&=& \lim_{n \rightarrow \infty}\text{E}(Y_{n}-\text{E}(Y_n))^2 \\
&=& \lim_{n \rightarrow \infty}\text{Var}(Y_{n}) \\
&=& \lim_{n \rightarrow \infty} \frac{\text{Var(X)}}{n} = 0
\end{eqnarray} %]]></script>

<p>Từ đó thế vào (1) ta suy ra:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{eqnarray}\lim_{n \rightarrow \infty} P(\text{Z} \geq \epsilon^2) &\leq& \lim_{n \rightarrow \infty}\frac{\text{E(Z)}}{\epsilon^2} \\
&=& \lim_{n \rightarrow \infty} \frac{\text{Var(X)}}{n\epsilon^2} = 0\end{eqnarray} %]]></script>

<p>Mặt khác $P(\text{Z} \geq \epsilon^2) \geq 0$ nên suy ra $\lim_{n \rightarrow \infty}P(\text{Z} \geq \epsilon^2) = 0$.
Suy ra điều phải chứng minh. Mấu chốt của chứng minh bất đẳng thức này là chúng ta phải phát hiện được tính chất $\text{Var}(Y_{n}) = \frac{\text{Var(X)}}{n}$ là một đại lượng tiến dần về 0 khi $n$ tiến tới vô cùng.</p>

<h2 id="13-định-lý-giới-hạn-trung-tâm">1.3. Định lý giới hạn trung tâm</h2>

<p>Đây là một định lý rất nổi tiếng và quan trọng trong xác xuất thống kê. Định lý trung tâm (central limit theorem) cho rằng khi rút ra một mẫu con đủ lớn từ một mẫu tổng thể của biến $\text{X}$ có trung bình và phương sai hữu hạn thì giá trị trung bình của mẫu con sẽ hội tụ về trung bình của mẫu tổng thể. Chính nhờ định lý này chúng ta có thể rút ra được các tính chất của một biến ngẫu nhiên nhờ thu thập một mẫu con với kích thước đủ lớn. Các thông tin có thể suy diễn ra đó là các tham số của phân phối thông kê (trung bình, phương sai) và ước lượng khoảng tin cậy. Thật vậy:
Xét một biến ngẫu nhiên $\text{X}$ tuân theo phân phối chuẩn $\mathbf{N}(\mu, \sigma^2)$. Lấy một mẫu con đủ lớn $S_X = {X_1, X_2, \dots , X_n}$ có các quan sát độc lập với kích thước $n$ từ tổng thể $\text{X}$. Khi đó giá trị trung bình của chuỗi $\bar{X}$ sẽ tuân theo qui luật phân phối chuẩn $\mathbf{N}(\mu, \frac{\sigma^2}{n})$.</p>

<p>Nếu đặt $\text{Z}=\frac{\bar{\text{X}}-\mu}{\sigma\sqrt{n}}$ ta sẽ thu được một biến $\text{Z}$ tuân theo phân phối chuẩn hoá $\mathbf{N}(0, 1)$. Coi $\bar{\text{X}}$ là trung bình và $s_x^2$ là phương sai của $S_X$.</p>

<p>Khoảng tin cậy $1-\alpha$ của trung bình tổng thể có thể được ước lượng qua các trung bình và phương sai của $S_X$:</p>

<script type="math/tex; mode=display">[\bar{\text{X}}-u_{\alpha/2}\frac{s_{x}}{\sqrt{n}}, \bar{\text{X}}+u_{\alpha/2}\frac{s_{x}}{\sqrt{n}}]</script>

<h1 id="phần-2---xác-xuất">Phần 2 - Xác xuất</h1>

<h2 id="21-khái-niệm-biến-ngẫu-nhiên">2.1. Khái niệm biến ngẫu nhiên:</h2>

<p>Biến ngẫu nhiên là một đại lượng được sử dụng để đo lường kết quả của những sự kiện ngẫu nhiên. Chẳng hạn như $\mathbf{x} \in {1, 2, 3, 4, 5, 6}$ là các biến cố trong phép đo kết quả các lần tung một xúc xắc 6 mặt đồng chất thì $\mathbf{x}$ được coi là biến ngẫu nhiên.</p>

<p>Trong xác xuất thống kê có hai khái niệm biến ngẫu nhiên là biến ngẫu nhiên rời rạc và biến ngẫu nhiên liên tục. Biến ngẫu nhiên rời rạc là đại lượng mà các giá trị của nó nằm trong một tập hợp cho trước. Trái lại, biến ngẫu nhiên liên tục có miền giá trị là tập con thuộc $\mathcal{R}$ (tập số thực), có thể hữu hạn hoặc không hữu hạn.</p>

<p>Hàm phân phối xác xuất (<em>probability distribution function</em>) $p(x)$ của một biến ngẫu nhiên $\mathbf{x}$ rời rạc là một hàm số đo lường xác xuất xảy ra sự kiện $p(\mathbf{x} = x)$ của một biến cố. Như vậy $1 \geq p(x) \geq 0$ và tổng xác xuất của toàn bộ các khả năng trong không gian biến cố bằng 1, hay:</p>

<script type="math/tex; mode=display">\sum_{x \in \mathcal{S}} p(x) = 1</script>

<p>Trong đó $\mathcal{S}$ là không gian biến cố, chẳng hạn trường hợp tung đồng xu thì $\mathcal{S} = {1,2,3,4,5,6}$.</p>

<p>Khi biến ngẫu nhiên liên tục sẽ có vô số các giá trị có thể của $\mathbf{x}$. Vì vậy ta không thể biểu diễn khả năng xảy ra của toàn bộ sự kiện dưới dạng tổng xác xuất rời rạc. Khi đó tích phân sẽ được sử dụng thay thế.</p>

<script type="math/tex; mode=display">\int p(x) dx = 1</script>

<p>Trong trường hợp này thuật ngữ hàm mật độ xác xuất (<em>probability density function</em> - pdf) để thể hiện $p(x)$ thay vì hàm phân phối xác xuất (<em>probability distribution function</em>).</p>

<p>Như chúng ta đã biết tích phân của một hàm số $f(x)$ chính là diện tích nằm giữa đường cong đồ thị $y = f(x)$ và trục hoành. Như vậy, phần diện tích nằm dưới hàm mật độ xác xuất $p(x)$ và trên trục hoành luôn có giá trị là 1. Chẳng hạn như đồ thị hàm mật độ xác xuất của phân phối chuẩn như hình bên dưới:</p>

<p><img src="https://ds055uzetaobb.cloudfront.net/image_optimizer/1dbcc5a80e3fb541aa4678fcff58bb26ca717902.png" alt="normal distribution" width="300px" height="300px" style="display:block; margin-left:auto; margin-right:auto" /></p>

<blockquote>
  <p>Hàm mật độ xác xuất của phân phối chuẩn có phương trình $f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^\frac{-(x-\mu)^2}{2\sigma^2}$ là đường cong có hình quả chuông đối xứng 2 bên. Giá trị hàm mật độ xác xuất tại những điểm lùi về phía 2 đuôi trái và phải nhỏ dẫn và giá trị hàm mật độ xác xuất tại vị trí trung tâm $x=\mu$ là lớn nhất. Phần diện tích màu hồng nằm dưới đường cong hàm mật độ xác xuất và trục hoành có giá trị bằng 1.</p>
</blockquote>

<h1 id="22-phân-phối-xác-xuất-đồng-thời">2.2. Phân phối xác xuất đồng thời.</h1>

<p>Trường hợp trên là đối với không gian xác xuất chỉ gồm 1 biến cố. Trên thực tế có nhiều biến cố xảy ra có mối liên hệ với nhau và đòi hỏi phát xét đến những không gian xác xuất đồng thời của nhiều biến cố. Chúng ta sẽ thể hiện các xác xuất đồng thời thông qua hàm phân phối xác xuất đồng thời $p(x, y)$ biểu thị khả năng xảy ra đồng thời của cả 2 sự kiện $x$ và $y$.</p>

<p>Tổng các khả năng xảy ra của các biến cố trong không gian các biến cố đồng thời luôn bằng 1. Điều đó có nghĩa là:</p>

<p><strong>Nếu x, y rời rạc:</strong></p>

<script type="math/tex; mode=display">\sum_{x, y} p(x, y) = 1</script>

<p><strong>Nếu x, y liên tục:</strong></p>

<script type="math/tex; mode=display">\int {p(x, y)} dx dy = 1</script>

<p><strong>Nếu x rời rạc, y liên tục:</strong></p>

<script type="math/tex; mode=display">\sum_{x}\int p(x, y) dy = 1</script>

<h2 id="23-phân-phối-xác-xuất-biên">2.3. Phân phối xác xuất biên:</h2>

<p>Nếu chúng ta cố định một biến cố và tính tổng (đối với biến rời rạc) hoặc tích phân (đối với biến liên tục) các xác xuất chung $p(x, y)$ theo biến cố còn lại thì ta sẽ thu được hàm phân phối xác xuất của theo một biến. Hàm phân phối xác xuất này được gọi là xác xuất biên (<em>marginal probability</em>) được tính như sau:</p>

<p><strong>Biến rời rạc:</strong></p>

<script type="math/tex; mode=display">p(x) = \sum_{y} p(x, y)</script>

<script type="math/tex; mode=display">p(y) = \sum_{x} p(x, y)</script>

<p><strong>Biến liên tục:</strong></p>

<script type="math/tex; mode=display">p(x) = \int_{y} p(x, y) dy</script>

<script type="math/tex; mode=display">p(y) = \int_{x} p(x, y) dx</script>

<h2 id="24-xác-xuất-có-điều-kiện">2.4. Xác xuất có điều kiện:</h2>

<p>Xác xuất của $y$ theo điều kiện của $x$ kí hiệu là $p(y|x)$ còn được gọi là xác suất hậu nghiệm (posterior probability) trong thống kê bayesian (bayesian statistic) có công thức như sau:</p>

<script type="math/tex; mode=display">p(y|x) = \frac{p(x, y)}{p(x)}</script>

<p>Xác suất hậu nghiệm cho ta biết khả năng xảy ra của một biến cố (biến cố $y$) trong điều kiện đã xét đến khả năng xảy ra của các biến cố khác (biến cố $x$).</p>

<p>Ngoài ra xác suất $p(x)$ còn được gọi là xác suất tiên nghiệm (prior probability), tức xác suất dựa trên niềm tin hoặc kinh nghiệm đã biết từ trước, trước khi các dấu hiệu xác suất (chính là điều kiện $y$) xuất hiện.</p>

<p>Từ công thức xác suất trên suy ra:</p>

<script type="math/tex; mode=display">p(x, y) = p(x|y)p(y) = p(y|x)p(x)</script>

<p>Ví dụ xác suất có điều kiện: Xác xuất chiến thắng (biến cố $y$) trong điều kiện tung được xúc sắc mặt 6 (biến cố $x$) là:</p>

<script type="math/tex; mode=display">p(y|x = 6) = \frac{p(x, y = 6)}{p(x = 6)}</script>

<p>Khi đó $p(x = 6)$ thông thường sẽ bằng $\frac{1}{6}$ nếu khối xúc sắc là đồng chất chính là xác suất tiên nghiệm mà ta đã biết trước, ngay cả khi không cần đến điều kiện $y$ là người đó đã chiến thắng.</p>

<p>Xác suất $p(y |x=6)$ là xác suất hậu nghiệm cho biết khả năng chiến thắng trong điều kiện đã biết tung được mặt $x=6$.</p>

<p>Trong các mô hình classification, xác suất dự báo đối với input là quan sát $X$ sẽ là xác suất hậu nghiệm $P(Y=1 |X)$ trong điều kiện mẫu có các đặc trưng mẫu là $X$.</p>

<h2 id="25-công-thức-bayes">2.5. Công thức bayes</h2>

<p>Chúng ta có thể biểu diễn xác xuất có điều kiện của biến cố $y$ theo $x$ dựa trên xác xuất có điều kiện của biến cố $x$ theo $y$.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{eqnarray} p(y|x) & = &\frac{p(x, y)}{p(x)} \\ 
						  & = & \frac{p(x, y)}{\sum_{y} p(x, y)}\\ 
						  & = & \frac{p(x|y)p(y)}{\sum_{y}p(x|y)p(y)}\end{eqnarray} %]]></script>

<p><strong>Ví dụ</strong>: Gọi $y$ là biến cố khách hàng vỡ nợ, $x$ là thu nhập khách hàng. Tính xác xuất khách hàng vỡ nợ trong điều kiện khác hàng thu nhập dưới 10 triệu VND biết rằng $p(y=1) = 0.01$, $p(x&lt;10) = 0.2$ và xác suất khách hàng có thu nhập dưới 10 triệu trong điều kiện vỡ nợ và không vỡ nợ lần lượt là 0.9 và 0.05.</p>

<p><strong>Lời giải</strong>: Từ điều kiện xác suất khách hàng có thu nhập dưới 10 triệu trong điều kiện vỡ nợ và không vỡ nợ lần lượt là 0.9 và 0.05 ta có $p(x&lt;10|y=1)=0.9$ và $p(x&lt;10|y=0)=0.05$.</p>

<p>Áp dụng công thức bayes:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{eqnarray} p(y=1|x<10) & = &\frac{p(x<10, y=1)}{p(x<10)} \\ 
							   & = & \frac{p(x<10, y=1)}{\sum_{y} p(x<10, y)}\\ 
							   & = & \frac{p(x<10 \|y=1)p(y=1)}{p(x<10 \|y=1)p(y=1)+p(x<10 \|y=0)p(y=0)}\\
							   & = & \frac{0.9 \times 0.01}{0.9 \times 0.01 + 0.05 \times 0.99} \\
							   & = & \frac{0.009}{0.009+0.0495} = 0.153846\end{eqnarray} %]]></script>

<p>Điểm mấu chốt của công thức bayes đó là chúng ta có thể tính được xác suất có điều kiện khi đã biết phân phối xác suất ngược lại của điều kiện theo biến cố cần tính xác suất.</p>

<h1 id="phần-3---kiểm-định-và-phân-phối-thống-kê">Phần 3 - Kiểm định và phân phối thống kê</h1>

<h2 id="31-phân-phối-thống-kê">3.1. Phân phối thống kê</h2>
<p>Thống kê là bộ môn khoa học dựa trên các qui luật số lớn. Từ thời kì cổ đại các nhà toán học đã nhận ra một số qui luật của thống kê chẳng hạn như khi tung một đồng xu đồng chất thì xác xuất nhận được các mặt xấp và ngửa đều bằng nhau và bằng 0.5. Chính qui luật đơn giản này đã hình thành nên một phân phối nổi tiếng về xác xuất là phân phối bernouli cho biết khả năng để xảy ra một biến cố $K$ trong một phép thử ngẫu nhiên là $\lambda_K \in [0, 1]$. Từ định nghĩa về phân phối bernouli bạn đọc đã hiểu được phân phối là gì rồi chứ? Phân phối chính là đặc trưng cho sự phân bố của các biến ngẫu nhiên trên toàn tập xác định của nó. Trong tự nhiên có những qui luật phân phối tri phối hầu hết các nhân tố, chúng có thể mô hình hoá được và đúng với số lớn mà ta sẽ tìm hiểu ở bên dưới. Nhưng trước tiên chúng ta sẽ làm quen với các khái niệm trong phân phối.</p>
<ol>
  <li><strong>Hàm mật độ xác xuất và phân phối xác xuất</strong>:
<br />
Trong thống kê chúng ta có rất nhiều các kiểu phân phối khác nhau. Trong đó có những phân phối cơ bản và thông dụng nhất bao gồm: phân phối chuẩn, t-student, Chi-square, Fisher, Bernouli và Poission. Một phân phối được đặc trưng bởi 1 hàm số thể hiện giá trị của phân phối xảy ra tại mỗi một điểm. Tuỳ thuộc vào biến cố là liên tục hay rời rạc mà tên hàm định nghĩa của chúng có thể khác nhau. Trong trường hợp biến liên tục hàm đại diện cho một phân phối được gọi là mật độ xác xuất (<em>pdf - probability density function</em>) và tên gọi hàm phân phối xác xuất (<em>pmf - probability mass function</em>) được sử dụng khi biến rời rạc. 
<br />
 Cả 2 thường được kí hiệu là $f_X(x)$ để biểu thị hàm số của biến cố $\text{X}$. Giá trị của chúng đều lớn hơn hoặc bằng 0 vì nếu nhỏ hơn 0 trong một miền rất nhỏ có thể dẫn tới tích phân âm trong miền đó, tức là xác xuất của biến cố là âm, điều này là vô lý. Có một sự khác biệt chính giữa <em>pdf</em> và <em>pmf</em> đó là giá trị của <em>pdf</em> có thể lớn hơn 1 trong khi <em>pmf</em> luôn nhỏ hơn 1. Sở dĩ điều này xảy ra là vì với các biến rời rạc xác xuất trên toàn miền bằng 1 và bằng tổng các xác xuất thành phần (tổng của các hàm <em>pmf</em> tại mỗi khả năng). Do đó giá trị của <em>pmf</em> không vượt qua 1. Trái lại, khi biến liên tục xác xuất toàn miền được tính bằng tích phân trên miền đó của hàm <em>pdf</em>. Một hàm số lớn hơn 1 vẫn có thể cho giá trị tích phân nhỏ hơn 1 nên <em>pdf</em> hoàn toàn có thể có giá trị lớn hơn 1. Cụ thể hơn chúng ta có thể lấy ví dụ về phân phối đều (<em>uniform distribution</em>) là phân phối có miền xác định trên đoạn $[a, b]$ sao cho xác xuất của chúng luôn bằng nhau tại mọi điểm trên miền xác định.
<br />
 Phương trình hàm mật độ xác xuất <em>pdf</em> có dạng:
<script type="math/tex">% <![CDATA[
\begin{equation}
          f_X(x) = \left\{
           \begin{array}{l l}
             \frac{1}{b-a} & \quad  a < x < b\\
             0 & \quad x < a \textrm{ or } x > b
           \end{array} \right.
         \end{equation} %]]></script></li>
</ol>

<p><img src="https://www.probabilitycourse.com/images/chapter4/PDF-Uniform_b.png" alt="uniform distribution" width="300px" height="300px" style="display:block; margin-left:auto; margin-right:auto" /></p>

<blockquote>
  <p>Hình 2: Đồ thị hàm mật độ xác xuất của phân phối đều trên đoạn $[a, b]$. Khi $b-a &lt; 1$ thì hàm mật độ xác xuất có thể lớn hơn 1.</p>
</blockquote>

<ol>
  <li><strong>Hàm phân phối xác xuất tích luỹ</strong>: 
<br />
Một định nghĩa nữa rất quan trọng đo lường xác xuất của phân phối xảy ra tại một miền giá trị bất kì trong không gian xác xuất, đó là hàm phân phối xác xuất tích luỹ (<em>cdf - cumulative distribution function</em>). Giá trị của hàm phân phối xác xuất tích luỹ chính là tích phân của mật độ xác xuất hoặc tổng của hàm phân phối xác xuất. Do đó kí hiệu của nó thường là $F_X(x)$. Hàm <em>cdf</em> được biểu thị trên đồ thị như thế nào? Hẳn chúng ta còn nhớ khái niệm về tích phân đã từng học tại THPT, đây chính là phần diện tích nằm dưới đồ thị của hàm số và trục hoành. Do đó khi biểu diễn một hàm mật độ xác xuất ta có hàm phân phối xác xuất của nó sẽ là phần diện tích dưới phương trình hàm mật độ và trên trục hoành. Chẳng hạn trong phân phối chuẩn ta có hàm phân phối xác xuất tích luỹ của $\text{X}$ trong miền giá trị $\text{X} &lt; 1$ chính là diện tích phần gạch chéo.</li>
</ol>

<p><img src="http://work.thaslwanter.at/Stats/html/_images/PDF_CDF.png" alt="cummulative distribution function" width="600px" height="300px" style="display:block; margin-left:auto; margin-right:auto" /></p>

<blockquote>
  <p>Hình 3: Diện tích biểu diễn hàm phân phối xác xuất $F_X(1)$ (phần gạch chéo).</p>
</blockquote>

<h2 id="32-phân-phối-chuẩn">3.2. Phân phối chuẩn.</h2>

<p>Phân phối chuẩn là phân phối kinh điển nhất trong thống kê. Nó được tìm ra bởi nhà toán học Gaussian (ông vua của các nhà toán học) nên còn được gọi là phân phối Gaussian. Người ta từng ví rằng việc tìm ra qui luật phân phối chuẩn quan trọng giống như việc tìm ra 3 định luật của Newton trong vật lý cổ điển. Người Đức tự hào về phân phối chuẩn đến mức đã cho in hình quả chuông chuẩn trên tờ tiền của họ.</p>

<p><img src="https://www.kleinbottle.com/images/10Deutschmarksbellcurve.jpg" width="500px" height="300px" style="display:block; margin-left:auto; margin-right:auto" /></p>

<blockquote>
  <p>Hình 4: Hình ảnh phân phối chuẩn bên cạnh nhà toán học Gaussian trên đồng tiền Đức.</p>
</blockquote>

<p>Quay trở lại lý thuyết, phân phối này được mô tả bởi hai tham số: trung bình $\mu$ và phương sai $\sigma^2$. Giá trị của $\mu$ là vị trí trung tâm của đáy phân phối có giá trị của hàm mật độ xác xuất là cao nhất. Phân phối có độ rộng đáy càng lớn khi $\sigma^2$ lớn, điều này chứng tỏ khoảng giá trị của biến biến động mạnh, và ngược lại.
Hàm mật độ xác suất của phân phối này được định nghĩa là:</p>

<script type="math/tex; mode=display">f(x) = \frac{1}{\sqrt{2\pi \sigma^2}}\exp \left( -\frac{(x - \mu)^2}{2\sigma^2}\right)</script>

<p>Nếu một biến ngẫu nhiên $\text{X} \sim \mathbf{N}(\mu, \sigma^2)$. Với mức độ tin cậy $(1-\alpha)$ ta sẽ có các định nghĩa sau đây:</p>
<ul>
  <li>Khoảng tin cậy 2 phía: <script type="math/tex">\mu - u_{\alpha/2}.\sigma \leq \text{X} \leq \mu + u_{\alpha/2}.\sigma</script></li>
  <li>Khoảng tin cậy trái: <script type="math/tex">X \leq \mu - u_{\alpha}.\sigma</script></li>
  <li>Khoảng tin cậy phải: <script type="math/tex">X \geq \mu + u_{\alpha}.\sigma</script></li>
</ul>

<p>Với $u_{\alpha}$ được gọi là giá trị tới hạn (critical value) tại mức ý nghĩa $\alpha$ của phân phối. Về bản chất đây chính là hàm ngược của hàm phân phối xác xuất tích luỹ. Tức là nếu ta có:
<script type="math/tex">P(\text{X} \geq a) = \alpha</script> thì giá trị $u_\alpha = a$.</p>

<p>Khoảng tin cậy 2 phía có xác xuất xảy ra là $1-\alpha$ được sử dụng để kiểm định giả thuyết dấu bằng. Các khoảng tin cậy 2, 3 có xác xuất xảy ra là $\alpha$ được sử dụng trong lần lượt giả thuyết nhỏ nhơn và lớn hơn. Cụ thể về giả thuyết dấu bằng và giả thuyết nhỏ hơn, lớn hơn là gì ta cùng tìm hiểu sau đây.</p>

<p><strong>Giả thuyết dấu bằng</strong>
Giả sử ta có một giả thuyết rằng trung bình của $\text{X}$ là $\mu_0$. Kiểm chứng giả thuyết này với mức độ tin cậy là 95%. Khi đó ta gọi đây là trường hợp kiểm định giả thuyết dấu bằng gồm 2 vế giả thuyết:</p>
<ul>
  <li>$H_0$-giả thuyết dấu bằng (null hypothesis) bởi nó không có thực trong hiện tại mà ta đang cần phải kiểm chứng. Tên gọi dấu bằng của giả thuyết này là bởi trong tóm tắt của nó thường là một biểu thức dấu bằng.</li>
  <li>$H_1$-giả thuyết thay thế (alternative hypothesiss) là giả thuyết đối của giả thuyết $H_0$.</li>
</ul>

<p>Biểu diễn 2 giả thuyết này như sau:</p>

<script type="math/tex; mode=display">\begin{equation}
            \left\{
              \begin{array}{l l}
                H_0: \text{X} = \mu\\
                H_1: \text{X} \neq \mu
              \end{array} \right.
            \end{equation}</script>

<p>Với mức ý nghĩa $(1-\alpha)$ thì miền chấp nhận giả thuyết $H_0$ chính là</p>

<script type="math/tex; mode=display">\mathcal{D} = \{\text{X}\sim \mathbf{N}(\mu, \sigma^2)|\mu - u_{\alpha/2}.\sigma \leq \text{X} \leq \mu + u_{\alpha/2}.\sigma\}</script>

<p>Mức ý nghĩa ở đây có thể hiểu là khả năng chắc chắn để giả thuyết $H_0$ xảy ra. Nếu mức ý nghĩa là 95%, ta có thể khẳng định chắc rằng khả năng rơi vào miền $\mathcal{D}$ của $\text{X}$ là 95%.</p>

<p>Trên thực tế xác xuất tính theo phân phối chuẩn</p>

<script type="math/tex; mode=display">P(\mu - u_{\alpha/2}.\sigma \leq \text{X} \leq \mu + u_{\alpha/2}.\sigma) = 1-\alpha</script>

<p>Lưu ý khi xác định chấp nhận hay bác bỏ một giả thuyết ta luôn phải đi kèm với điều kiện kết luận ở mức ý nghĩa bao nhiêu %.</p>

<p><strong>Giả thuyết lớn hơn</strong>
Cặp giả thuyết lớn hơn dùng để kiểm chứng một nhận định giá trị của một biến lớn hơn một hằng số nào đó. giả thuyết này sẽ khác với cặp giả thuyết dấu bằng ở chỗ trong phát biểu của nó giả thuyết $H_1$ là một dấu lớn nhỏ hơn thay vì dấu khác. Biểu diễn cặp giả thuyết lớn hơn như sau:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
            \left\{
              \begin{array}{l l}
                H_0: \text{X} = \mu\\
                H_1: \text{X} < \mu
              \end{array} \right.
            \end{equation} %]]></script>

<p>Với mức ý nghĩa $(1-\alpha)$, miền chấp nhận giả thuyết $H_0$ là</p>

<script type="math/tex; mode=display">\mathcal{D} = \{\text{X}\sim \mathbf{N}(\mu, \sigma^2)|X \geq \mu - u_{\alpha}.\sigma\}</script>

<p>Xác xuất</p>

<script type="math/tex; mode=display">P(X \geq \mu - u_{\alpha}.\sigma) = 1-\alpha</script>

<p><strong>Giả thuyết nhỏ hơn</strong>
Được sử dụng để kiểm chứng một nhận định giá trị của một biến nhỏ hơn một hằng số nào đó. Hoàn toàn tương tự như cặp giả thuyết lớn hơn ta có biểu diễn của cặp giả thuyết nhỏ hơn.</p>

<script type="math/tex; mode=display">\begin{equation}
            \left\{
              \begin{array}{l l}
                H_0: \text{X} = \mu\\
                H_1: \text{X} > \mu
              \end{array} \right.
            \end{equation}</script>

<p>Với mức ý nghĩa $(1-\alpha)$, miền chấp nhận giả thuyết $H_0$ của giả thuyết này là</p>

<script type="math/tex; mode=display">\mathcal{D} = \{\text{X}\sim \mathbf{N}(\mu, \sigma^2)|X \leq \mu - u_{\alpha}.\sigma\}</script>

<p>Xác xuất</p>

<script type="math/tex; mode=display">P(X \leq \mu - u_{\alpha}.\sigma) = 1-\alpha</script>

<h2 id="33-t-student">3.3. t-student.</h2>

<p>Như chúng ta đã biết hầu hết các mẫu ngẫu nhiên với kích thước đủ lớn đều tuân theo qui luật phân phối chuẩn. Tuy nhiên nhược điểm của phân phối chuẩn đó là chúng ta phải biết trước được các tham số về kì vọng và phương sai của tổng thể thì mới xác định được hình dạng của phân phối. Trong khi không phải khi nào cũng đo lường được những tham số này vì tổng thể là quá lớn. Do đó một phân phối khác được phát triển có hình dạng gần tương tự như phân phối chuẩn hoá nhưng ứng dụng trên phương sai và độ lệch chuẩn của mẫu thay vì tổng thể, đó chính là phân phối t-student.</p>

<p>t-student là phân phối thuộc họ các phân phối liên tục được phát triển trong quá trình ước lượng trung bình của các chuỗi phân phối chuẩn nhưng kích thước mẫu nhỏ và phương sai của tổng thể là chưa xác định. t-student được sử dụng chủ yếu trong các trường hợp sau:</p>

<ul>
  <li>Kiểm định về khác biệt giữa 2 trung bình mẫu.</li>
  <li>Tìm khoảng tin cậy về sự khác biệt giữa 2 trung bình mẫu.</li>
  <li>Sử dụng tìm khoảng tin cậy của các hệ số ước lượng và tính P-value của các hệ số ước lượng trong hồi qui tuyến tính.</li>
</ul>

<p>Phát biểu của phân phối t-student như sau:</p>

<p>Nếu ta lấy một mẫu con ${X_1, X_2, \dots, X_n}$ con kích thước $n$ từ tổng thể của biến ngẫu nhiên $\text{X}$ phân phối chuẩn có kì vọng $\mu$ nhưng chưa biết về phương sai của nó. Khi đó sai số của các phần tử trong mẫu so với $\mu$ sau khi nhân với $\frac{1}{S\sqrt{n-1}}$ là đại lượng tuân theo qui luật phân phối t-student với bậc tự do $n-1$. Trong đó $S$ là phương sai của mẫu. Tức là: $S^2 = \frac{\sum_{i=1}^{n}(X_i-\bar X_i)^2}{n-1}$.</p>

<p>Trong trường hợp đã biết phương sai $\sigma^2$ của tổng thể:
<script type="math/tex">\text{Z} = \frac{\text{X}-\mu}{\sigma\sqrt{n}} \sim \mathbf{N}(0, 1)</script>
Trong trường hợp chưa biết phương sai tổng thể:
<script type="math/tex">\text{Z} = \frac{\text{X}-\mu}{S\sqrt{n-1}} \sim \mathbf{T}(n-1)</script>
Do là một phân phối thay thế cho phân phối chuẩn hoá trong trường hợp chưa xác định phương sai tổng thể nên hình dạng của phân phối t-student cũng gần như phân phối chuẩn phối chuẩn hoá. Trên thực tế nếu $\text{Z}\sim \mathbf{T}(n-1)$ thì $\text{E(Z)} = 0$ và $\text{Var(Z)} = \frac{n}{n-2}$ (với $n &gt; 2$, còn lại không xác định). Trong trường hợp bậc tự do vô cùng lớn, phân phối t-student hội tụ về phân phối chuẩn hoá.</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Student_t_pdf.svg/650px-Student_t_pdf.svg.png" width="400px" height="300px" style="display:block; margin-left:auto; margin-right:auto" /></p>

<blockquote>
  <p>Hình 5: Hình dạng của phân phối t-student với bậc tự do lần lượt là $1, 2, 5, +\infty$</p>
</blockquote>

<h2 id="34-phân-phối-chi-square">3.4. Phân phối Chi-square</h2>

<p>Phân phối chi-square kí hiệu là $\chi^2$ là một phân phối có bậc tự do. Một phân phối chi-square được tạo thành từ tổng bình phương của các phân phối chuẩn hóa mà bậc tự do của nó chính bằng số lượng các phần tử trong tổng. Hay nói cách khác: $X_1, X_2, \dots, X_n$ là tợp hợp gồm $n$ biến ngẫu nhiên, độc lập tuyến tính và phân phối chuẩn hóa thì biến <script type="math/tex">\text{Y} = \sum_{i=1}^{n}X_i^2</script> là một phân phối chi-square với bậc tự do $n$. Ta kí hiệu $\text{Y} \sim \chi^{2}_n$.</p>

<p>Bên dưới là đồ thị của hàm mật độ xác xuất của phân phối chi-square.</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Chi-square_pdf.svg/482px-Chi-square_pdf.svg.png" width="400px" height="300px" style="display:block; margin-left:auto; margin-right:auto" /></p>

<blockquote>
  <p>Hình 6: Hàm mật độ xác xuất (<em>pdf</em>) của phân phối chi-square với bậc tự do từ 1 đến 9</p>
</blockquote>

<p>Ta nhận thấy chi-square là một phân phối lệch trái. Khi bậc tự do của nó càng nhỏ thì đồ thị lệch trái đồng thời phần đuôi phía bên phải càng mỏng và trái lại.</p>

<p>Phân phối chi-square là một trong những phân phối phổ biến nhất trong suy diến thống kê, thường được sử dụng trong các kiểm định giả thuyết và tìm khoảng tin cậy. Một số ứng dụng cụ thể của chi-square:</p>

<ul>
  <li>Kiểm tra tính phù hợp (<em>goodness of fit</em>) của một phân phối thực nghiệm theo một phân phối lý thuyết.
Chẳng hạn chúng ta có một chuỗi thực nghiệm $\text{O}$ và một chuỗi lý thuyết phân phối chuẩn $\text{E}$ có cùng kích thước mẫu $n$. Chúng ta nghi ngờ rằng $\text{O}$ và $\text{E}$ có cùng phân phối. Khi đó tổng bình phương sai số của $\text{E}$ và $\text{O}$ sẽ tuân theo phân phối chi-square bậc tự do $n$. 
<script type="math/tex">\chi^{2} = \sum_{i=1}^{n}\frac{(O_i-E_i)^2}{E_i}</script>
    <ul>
      <li>$\chi^{2}$: Gía trị kiểm định của giả thuyết 2 chuỗi có cùng phân phối, tuân theo phân phối chi-square bậc tự do $n-1$ (Lưu ý đối với mẫu con thì bậc tự do là $n-1$ còn đối với tổng thể bậc tự do là $n$).</li>
      <li>$O_i$: quan sát thứ $i$ của chuỗi thực nghiệm $\text{O}$.</li>
      <li>$E_i$: quan sát thứ $i$ của chuỗi lý thuyết nghiệm $\text{E}$.</li>
      <li>$n$: Số lượng các quan sát.</li>
    </ul>

    <p>Để kết luận 2 chuỗi có cùng phân phối hay không, ta sẽ so sánh gía trị kiểm định của giả thuyết $\chi^{2}$ với giá trị tới hạn $\chi^{2(1-\alpha)}_{n-1}$.
  <br />
<strong>Ví dụ</strong>: Một súc sắc 6 mặt được ném 60 lần. Số lần xuất hiện các mặt 1, 2, 3, 4, 5 và 6 lần lượt là 5, 8, 9, 8, 10 và 20. Kiểm định giả thuyết rằng có sự khác biệt về khả năng nhận được các mặt theo kểm định Pearson chi-squared ở mức ý nghĩa 95%?
  <br />
Kì vọng là khả năng nhận được các các mặt của xác xuất là như nhau, do đó mỗi mặt được dự kiến xuất hiện là bằng nhau và bằng 60/6 = 10. Các kết quả được lập bảng như sau:</p>
  </li>
</ul>
<table class="wikitable" align="center" border="1">
<tbody><tr>
<th style="padding:0 1em;"><i>i</i>
</th>
<th style="padding:0 1em;"><i>O<sub>i</sub></i>
</th>
<th style="padding:0 1em;"><i>E<sub>i</sub></i>
</th>
<th><i>O<sub>i</sub></i> −<i>E<sub>i</sub></i>
</th>
<th>(<i>O<sub>i</sub></i> −<i>E<sub>i</sub></i> )<sup>2</sup>
</th>
<th><span class="sfrac nowrap" style="display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;"><span style="display:block; line-height:1em; margin:0 0.1em;">(<i>O<sub>i</sub></i> −<i>E<sub>i</sub></i> )<sup>2</sup></span><span class="visualhide">/</span><span style="display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;"><i>E<sub>i</sub></i></span></span>
</th></tr>
<tr>
<td>1</td>
<td>5</td>
<td>10</td>
<td>−5</td>
<td>25</td>
<td>2.5
</td></tr>
<tr>
<td>2</td>
<td>8</td>
<td>10</td>
<td>−2</td>
<td>4</td>
<td>0.4
</td></tr>
<tr>
<td>3</td>
<td>9</td>
<td>10</td>
<td>−1</td>
<td>1</td>
<td>0.1
</td></tr>
<tr>
<td>4</td>
<td>8</td>
<td>10</td>
<td>−2</td>
<td>4</td>
<td>0.4
</td></tr>
<tr>
<td>5</td>
<td>10</td>
<td>10</td>
<td>0</td>
<td>0</td>
<td>0
</td></tr>
<tr>
<td>6</td>
<td>20</td>
<td>10</td>
<td>10</td>
<td>100</td>
<td>10
</td></tr>
<tr>
<td colspan="5" style="text-align:right;">Sum</td>
<td>13.4
</td></tr></tbody></table>
<p>Bậc của tự do chính là $n-1 = 5$. Gía trị tới hạn đuôi lớn hơn của phân phối chi-square tại mức tin cậy 95% được cho ở bảng bên dưới</p>
<table class="wikitable" align="center" border="1">
<tbody><tr>
<th rowspan="2">Degrees<br /> of<br />freedom
</th>
<th colspan="5">Probability less than the critical value
</th></tr>
<tr>
<th>0.90</th>
<th><i>0.95</i></th>
<th>0.975</th>
<th><i>0.99</i></th>
<th>0.999
</th></tr>
<tr>
<th><i>5</i>
</th>
<td>9.236</td>
<td><i>11.070</i></td>
<td>12.833</td>
<td><i>15.086</i></td>
<td>20.515
</td></tr></tbody></table>

<p>Gía trị kiểm định giả thuyết là 13.4 vượt qua giá trị tới hạn tại mức ý nghĩa 95%. Do đó bác bỏ giả thuyết dấu bằng $H_0$ và kết luận rằng xác xuất khả năng xảy ra các mặt của súc sắc là khác nhau tại mức ý nghĩa 95%.</p>

<ul>
  <li>Kiểm tra tính phụ thuộc giữa các biến phân loại dựa trên bảng cross table.
<br />
Ví dụ: Để dễ minh họa tôi xin lấy ví dụng từ wikipedia. Chúng ta có số liệu về 100 học sinh được lựa chọn ngẫu nhiên theo 2 tiêu chí giới tính (Sex) và tay thuận (Handedness) được rút ra từ một tổng thể rất lớn một cách ngẫu nhiên. Bảng thông kê cross table cho thấy như dưới:</li>
</ul>
<table style="margin-left:auto;margin-right:auto;text-align:center;" border="1">
<tbody><tr>
<th style="background:linear-gradient(to top right,#eaecf0 49.5%,#aaa 49.5%,#aaa 50.5%,#eaecf0 50.5%);line-height:1;">
    <div style="margin-left:2em;text-align:right;">Handed-<br />ness</div>
    <div style="margin-right:2em;text-align:left;">Sex</div>
    </th>
    <th>Right handed</th>
    <th>Left handed</th>
    <th>Total
    </th></tr>
    <tr>
    <th>Male
    </th>
    <td>43</td>
    <td>9</td>
    <td>52
    </td></tr>
    <tr>
    <th>Female
    </th>
    <td>44</td>
    <td>4</td>
    <td>48
    </td></tr>
    <tr>
    <th>Total
    </th>
    <td>87</td>
    <td>13</td>
    <td>100
</td></tr>
</tbody>
</table>
<p>Để kiểm tra xem liệu giới tính có ảnh hưởng lên tay thuận của học sinh hay không chúng ta có thể sử dụng kiểm định Pearson chi-squared tìm ra sự khác biệt giữa các nhóm tay thuận tay trái và tay phải theo giới tính.</p>
<ul>
  <li>Ước lượng khoảng tin cậy cho phương sai của một chuỗi các độ lệch chuẩn. 
<br />
Thường được áp dụng trong tìm khoảng tin cậy trong phân tích chuỗi thời gian. Thu thập số liệu biến thiên tỷ suất lợi nhuận của các mã chứng khoán trong vòng 36 tháng ta sẽ thu được một chuỗi các độ lệch chuẩn $\sigma_1^2, \sigma_2^2,…,\sigma_{36}^2$. Tìm khoảng tin cậy 95% độ giao động của chuỗi chứng khoán trong tháng tiếp theo.</li>
</ul>

<h2 id="35-phân-phối-fisher">3.5. Phân phối Fisher</h2>

<p>Phân phối Fisher rất thường xuyên xuất hiện trong kinh tế lượng vì ứng dụng trong việc tìm sự khác biệt giữa 2 phương trình hồi qui, và phân tích phương sai ANOVA. Bởi vì được nghĩ ra bởi nhà thống kê học nổi tiếng Fisher người được coi là đặt nền móng cho ngành thống kê hiện đại nên tên của phân phối được đặt theo tên ông. Phân phối Fisher được xây dựng dựa trên một phép chia của 2 đại lượng ngẫu nhiên tuân theo qui luật phân phối có bậc tự do. Do đó một phân phối Fisher đặc trưng bởi 2 bậc tự do, một của tử số và một của mẫu số.</p>

<p>Một số tính chất của phân phối Fisher:</p>

<ul>
  <li>
    <p>Nếu $\text{X} \sim \mathbf{T}(n)$ thì $\text{X}^2 \sim \mathbf{F}(1, n)$. Đây chính là lý do tại sao kiểm định giá trị của một hệ số ước lượng trong phương trình hồi qui có ý nghĩa thống kê hay không vừa có thể được thực hiện qua phân phối Fisher và phân phối t-student mà kết quả thu được là tương đương.</p>
  </li>
  <li>
    <p>Phân phối Fisher và phân phối chi-square có mối quan hệ gần gũi. Nếu 2 biến ngẫu nhiên $\text{X} \sim \chi^{2}<em>{d_1}$ và $\text{Y} \sim \chi^{2}</em>{d2}$ thì khi đó thương giữa chúng là <script type="math/tex">\frac{\text{X}/d_1}{\text{Y}/d_2} \sim \mathbf{F}(d_1, d_2)</script></p>
  </li>
  <li>
    <p>Nếu $\text{X} \sim \mathbf{F}(d_1, d_2)$ thì $\text{X}^{-1} \sim \mathbf{F}(d_2, d_1)$</p>
  </li>
</ul>

<p>Ví dụ về ứng dụng của kiểm định Fisher về ý nghĩa của các hệ số ước lượng trong phương trình hồi qui như sau:</p>

<p>Một tập hợp gồm $p$ biến độc lập $\text{X}_1, \dots, \text{X}_p$ và biến phụ thuộc $\text{Y}$. Hồi qui toàn bộ $p$ biến giải thích ta thu được phương trình hồi qui:</p>

<script type="math/tex; mode=display">a_0 + a_1\text{X}_1 + \dots + a_p\text{X}_n + \epsilon= \text{Y}</script>

<p>với $a_i$ là các hệ số tự do, $\epsilon$ là thành phân đại diện cho sai số ngẫu nhiên.</p>

<p>Phương trình hồi qui trên có tổng bình phương sai số (RSS - residual sum square) là</p>

<script type="math/tex; mode=display">\text{RSS}_1 = \sum_{i=1}^{n} \epsilon_{i}^2</script>

<p>với $n$ là số quan sát.</p>

<p>Kiểm tra hệ số p-value của ước lượng cho thấy các biến từ $X_{q}, X_{q+1}, \dots, X_{p}, q&lt;p$ không có ý nghĩa thống kê (p-value &gt; 0.05). Loại các biến này ra khỏi phương trình hồi qui ta thu được phương trình hồi qui thứ 2.</p>

<script type="math/tex; mode=display">a_0 + a_1\text{X}_1 + \dots + a_q\text{X}_q + u= \text{Y}</script>

<p>Phương trình này có tổng bình phương sai số là</p>

<script type="math/tex; mode=display">\text{RSS}_2 = \sum_{i=1}^{n} u_{i}^2</script>

<p>Kiểm định giả thuyết rằng các hệ số $a_{q}, a_{q+1}, \dots, a_{p}$ không có ý nghĩa thống kê.</p>

<p>Khi đó chúng ta có cặp giải thuyết kiểm định:</p>

<script type="math/tex; mode=display">\begin{equation}
            \left\{
              \begin{array}{l l}
                H_0: a_q = a_{q+1} = \dots = a_{p} = 0 \\
                H_1: \sum_{i=q}^{p} a_i^2 > 0 
              \end{array} \right.
            \end{equation}</script>

<p>Việc chấp nhận giả thuyết $H_0$ tương đương với việc chấp nhận rằng 2 phương trình hồi qui như nhau. 
Do đó ta qui bài toán về kiểm định $\text{RSS}_1 = \text{RSS}_2$. Ta nhận thấy $\text{RSS}_1$ và $\text{RSS}_2$ đều là những phân phối chi-square nên thương của chúng sẽ có dạng một phân phối fisher. Ý tưởng là chúng ta cần tạo ra một phân phối fisher có thể dùng để tính toán giá trị tới hạn và đối chiếu với giá trị kiểm định. Đó chính là:</p>

<script type="math/tex; mode=display">\text{F} = \frac{(\text{RSS}_1 - \text{RSS}_2)/(p-q)}{\text{RSS}_2/(n-p)}</script>

<p>có phân phối $\mathbf{F}(p-q, n-p)$.</p>

<p>Để bác bỏ $H_0$ với mức tin cậy 95% ta cần $\text{F} &gt; F_{0.05}(p-q, n-p)$ và trái lại. Chúng ta có thể biểu diễn miền bác bỏ giả thuyết $H_0$ là phần diện tích ở phía đuôi bên phải như hình bên dưới:</p>

<p><img src="http://oak.snr.missouri.edu/nr3110/images/Fdist-fig.jpeg" height="300px" width="400px" style="display:block; margin-left:auto; margin-right:auto" /></p>

<blockquote>
  <p>Hình 7: Miền bác bỏ giả thuyết $H_0$ với mức độ tin cậy 95% của kiểm định fisher.</p>
</blockquote>


<script data-ad-client="ca-pub-4263248182804679" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<button onclick="topFunction()" id="myBtn" title="Go to top">Top</button>

<script src="/js/toc.js"></script>
<script src="/js/btnTop.js"></script>
<script type="text/javascript">
$(document).ready(function() {
    $('#toc').toc();
});
</script>
				</div>
			</div>
			<div class="col-md-2 hidden-xs hidden-sm">
				<a  href="/">
					<img width="100%" style="padding-bottom: 3mm;" src="/assets/images/logo.jpg" /> </a>
				<br>
				<nav>
					<div class="header">Khanh's site</div>
					<li><a style="text-align: left; color: #074B80"  href="https://www.facebook.com/TowardDataScience">phamdinhkhanh blog</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://www.facebook.com/groups/3235479620010379/">phamdinhkhanh AICode forum</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://kaggle.com/phamdinhkhanh">phamdinhkhanh kaggle</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://rpubs.com/phamdinhkhanh">phamdinhkhanh rpub</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://github.com/phamdinhkhanh">phamdinhkhanh github</a></li>
					<br>
					<div class="header">other's site</div>
					<li><a style="text-align: left; color: #074B80"  href="https://www.facebook.com/groups/machinelearningcoban/">machine learning cơ bản facebook</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://forum.machinelearningcoban.com/">machine learning cơ bản forum</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://machinelearningmastery.com">machine learning mastery</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://viblo.asia">viblosia</a></li>
					<br>
					<div class="header">Khóa học</div>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs109/">Xác suất thống kê(Probability): CS109</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs246/">Bigdata: CS246</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://cs231n.stanford.edu/">Computer vision cơ bản: CS231N</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs224n/">Natural Language Processing: CS224N</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs224w/">Khoá phân tích mạng lưới (analysis of network): CS224W</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://web.stanford.edu/class/cs20si/">Khóa học Tensorflow: CS20SI</a></li>
				</nav>
			</div>
		</div>
	</div>
	
</body>
</html>
