<!DOCTYPE html>
<html>

<head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#">
<meta charset="utf-8" />
<meta http-equiv='X-UA-Compatible' content='IE=edge'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>
<title>Khoa học dữ liệu</title>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
<!-- Style for main home page -->
<link rel="stylesheet" href="/assets/css/styles.css">
<link rel="stylesheet" href="/assets/css/styles_toc.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
<script data-ad-client="ca-pub-4263248182804679" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> 
<link href="https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300" rel="stylesheet">
<!-- <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet"> -->
<link href="https://fonts.googleapis.com/css?family=Roboto|Source+Sans+Pro" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Fira+Sans" rel="stylesheet">
<link rel="icon" type="image/jpg" href="assets/images/logo.jpg" sizes="32x32">
<link rel="canonical" href="https://phamdinhkhanh.github.io"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="author" content="Phạm Đình Khánh" />
<meta property="og:title" content="" />
<meta property="og:site_name" content="Khanh's blog" />
<meta property="og:url" content="https://phamdinhkhanh.github.io" />
<meta property="og:description" content="" />

<meta property="og:type" content="article" />
<meta property="article:published_time" content="" />


<meta property="article:author" content="Khanh" />
<meta property="article:section" content="" />

<link rel="alternate" type="application/atom+xml" title="Khanh's blog - Atom feed" href="/feed.xml" />
<style>
	
</style>
<!-- -- Import latext  -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
	skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
	inlineMath: [['$','$']]
  }
});
</script>

<!-- Google Analytics -->

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-89509207-1', 'auto');
// ga('send', 'pageview');
ga('send', 'pageview', {
'page': '/',
'title': ''
});
</script>


<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-KTCD8BX');</script>
<!-- End Google Tag Manager -->
</head>
<style>
body {
  padding: 0 7.5%;
}
</style>

<body>
	<div id="fb-root"></div>
	<!-- <script>(function(d, s, id) { -->
	  <!-- var js, fjs = d.getElementsByTagName(s)[0]; -->
	  <!-- if (d.getElementById(id)) return; -->
	  <!-- js = d.createElement(s); js.id = id; -->
	  <!-- js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.9"; -->
	  <!-- fjs.parentNode.insertBefore(js, fjs); -->
	<!-- }(document, 'script', 'facebook-jssdk'));</script> -->
	<br>
	<div content = "container">
		<div class="row">
			<div class="col-md-2 hidden-xs hidden-sm">
				<a  href="/">
					<img width="100%" style="padding-bottom: 3mm;" src="/assets/images/img.jpg" /> </a>
				<br>
				<nav>
					<div class="header">Latest</div>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/08/13/ModelMetric.html">Bài 46 - Đánh giá mô hình phân loại trong ML</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/08/09/ConditionalGAN.html">Bài 45 - Conditional GAN (CGAN)</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/07/25/GAN_Wasserstein.html">Bài 44 - Model Wasserstein GAN (WGAN)</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/07/13/GAN.html">Bài 43 - Model GAN</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/06/20/Unet.html">Bài 42 - Thực hành Unet</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/06/18/DeepLab.html">Bài 41 - DeepLab Sentiment Segmentation</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/06/10/ImageSegmention.html">Bài 40 - Image Segmentation</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/06/04/PhoBERT_Fairseq.html">Bài 39 - Thực hành ứng dụng BERT</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/05/31/CNNHistory.html">Bài 38 - Các kiến trúc CNN hiện đại</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/05/28/TransformerThemDauTV.html">Bài 37 - Transformer thêm dấu Tiếng Việt</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/05/23/BERTModel.html">Bài 36 - BERT model</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/05/05/MultitaskLearning_MultiBranch.html">Bài 35 - Multitask Learning - Multi Branch</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/04/22/MultitaskLearning.html">Bài 34 - Multitask Learning</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/04/15/TransferLearning.html">Bài 33 - Phương pháp Transfer Learning</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/04/09/TensorflowDataset.html">Bài 32 - Kĩ thuật tensorflow Dataset</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/04/03/AWS.html">Bài 31 - Amazon Virtual Machine Deep Learning</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/28/deployTensorflowJS.html">Bài 30 - Xây dựng Web AI trên tensorflow js</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/23/FlaskRestAPI.html">Bài 29 - Xây dựng Flask API cho mô hình deep learning</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/21/faceNet.html">Bài 28 - Thực hành training Facenet</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/12/faceNetAlgorithm.html">Bài 27 - Mô hình Facenet trong face recognition</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/10/DarknetGoogleColab.html">Bài 26 - Huấn luyện YOLO darknet trên google colab</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/03/09/DarknetAlgorithm.html">Bài 25 - YOLO You Only Look Once</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/02/17/ImbalancedData.html">Bài 24 - Mất cân bằng dữ liệu (imbalanced dataset)</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/02/11/NARSyscom2015.html">Bài 23 - Neural Attentive Session-Based Recommendation</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/01/17/ScoreCard.html">Bài 22 - Scorecard model</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2020/01/06/ImagePreprocessing.html">Bài 21 - Tiền xử lý ảnh OpenCV</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/12/26/Sorfmax_Recommendation_Neural_Network.html">Bài 20 - Recommendation Neural Network</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/12/12/ARIMAmodel.html">Bài 19 - Mô hình ARIMA trong time series</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/12/02/DeepLearningLayer.html">Bài 18 - Các layers quan trọng trong deep learning</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/11/22/HOG.html">Bài 17 - Thuật toán HOG (Histrogram of oriented gradient)</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/11/08/RFMModel.html">Bài 16 - Model RFM phân khúc khách hàng</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/11/04/Recommendation_Compound_Part1.html">Bài 15 - collaborative và content-based filtering</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/10/22/googleHeatmap.html">Bài 14 - Biểu đồ trên Google Map</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/10/05/SSDModelObjectDetection.html">Bài 13 - Model SSD trong Object Detection</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/09/29/OverviewObjectDetection.html">Bài 12 - Các thuật toán Object Detection</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/09/16/VisualizationPython.html">Bài 11 - Visualization trong python</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/09/08/LDATopicModel.html">Bài 10 - Thuật toán LDA - Xác định Topic</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/08/25/PyTorch_Torchtext_Tutorial.html">Bài 9 - Pytorch - Buổi 3 - torchtext module NLP</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/08/22/convolutional-neural-network.html">Bài 8 - Convolutional Neural Network</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/08/19/CorrectSpellingVietnamseTonePrediction.html">Bài 7 - Pytorch - Buổi 2 - Seq2seq model correct spelling</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/08/10/PytorchTurtorial1.html">Bài 6 - Pytorch - Buổi 1 - Làm quen với pytorch</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/07/15/PySparkSQL.html">Bài 5 - Model Pipeline - SparkSQL</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/06/18/AttentionLayer.html">Bài 4 -  Attention is all you need</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/05/10/Hypothesis_Statistic.html">Apenddix 1 - Lý thuyết phân phối và kiểm định thống kê</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/04/29/ModelWord2Vec.html">Bài 3 - Mô hình Word2Vec</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/04/22/Ly_thuyet_ve_mang_LSTM.html">Bài 2 - Lý thuyết về mạng LSTM part 2</a></li>
					
					<li><a style="text-align: left; color: #074B80"  href="/2019/01/07/Ky_thuat_feature_engineering.html">Bài 1 - Kĩ thuật feature engineering</a></li>
					
				</nav>
			</div>
			<div class="col-md-8 col-xs-12" style="z-index:1">
				<nav class="navbar navbar-inverse" style="background-color: #046897">
					<div class = "container-fluid">
						<div class = "navbar-header>
							<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
								<span class="icon-bar"></span>
								<span class="icon-bar"></span>
								<span class="icon-bar"></span>
							</button>
							<a class="navbar-brand" href="/">
								<span style="color:#FFF">Khoa học dữ liệu - Khanh's blog</span>
							</a>
						</div>
						<br>
						<br>
						<div class="collapse navbar-collapse navbar-right" id="myNavbar">
							<ul class="nav navbar-nav">
								<li><a href="/home"><span style="color: #fff"> Home</span></a></li>
								<li><a href="/about"><span style="color: #fff"> About</span></a></li>
								<!-- <li><a href="/da"><span style="color: #fff">Data Analytics</span></a></li> -->
								<!-- <li><a href="/cv"><span style="color: #fff">Computer Vision</span></a></li> -->
								<!-- <li><a href="/nlp"><span style="color: #fff">NLP</span></a></li> -->
								<!-- <li><a href="/code"><span style="color: #fff">Code</span></a></li> -->
								<li><a href="/book"><span style="color: #fff">Book</span></a></li>
							</ul>
						</div>
					</div>
				</nav>
				<div class="PageNavigation">
				</div>
				<h1 itemprop="name" class="post-title"></h1>
				<div id="bootstrap-overrides">
					<div>
<h2><p class="post-link" style="text-align: left; color: #204081; font-weight: bold">Bài 46 - Đánh giá mô hình phân loại trong ML</p></h2> 
<strong>13 Aug 2020 - phamdinhkhanh</strong>
</div>
<br/>
<div id="toc"></div>
<h1 id="1-đánh-giá-mô-hình">1. Đánh giá mô hình</h1>

<p>Trong quá trình xây dựng một mô hình machine learning, một phần không thể thiếu để biết được chất lượng của mô hình như thế nào đó chính là đánh giá mô hình.</p>

<p>Đánh giá mô hình giúp chúng ta lựa chọn được mô hình phù hợp nhất đối với bài toán của mình. Tuy nhiên để tìm được thước đo đánh giá mô hình phù hợp thì chúng ta cần phải hiểu về ý nghĩa, bản chất và trường hợp áp dụng của từng thước đo.</p>

<p>Chính vì vậy bài viết này sẽ cung cấp cho các bạn kiến thức về các thước đo cơ bản nhất, thường được áp dụng trong các mô hình phân loại trong machine learning nhưng chúng ta đôi khi còn chưa nắm vững hoặc chưa biết cách áp dụng những thước đo này sao cho phù hợp với từng bộ dữ liệu cụ thể.</p>

<p>Hãy cùng phân tích và tìm hiểu các thước đo này qua các ví dụ bên dưới.</p>

<h1 id="2-bộ-dữ-liệu">2. Bộ dữ liệu</h1>

<p>Giả định rằng chúng ta đang xây dựng một mô hình phân loại nợ xấu. Nhãn của các quan sát sẽ bao gồm GOOD (thông thường) và BAD (nợ xấu). Kích thước của các tập dữ liệu như sau:</p>

<ul>
  <li>Tập train: 1000 hồ sơ bao gồm 900 hồ sơ GOOD và 100 hồ sơ BAD.</li>
  <li>tập test: 100 hồ sơ bao gồm 85 hồ sơ GOOD và 15 hồ sơ BAD.</li>
</ul>

<p>Để thuận tiện cho diễn giải và đồng nhất với những tài liệu tham khảo khác về ký hiệu thì biến mục tiêu $y$ nhãn BAD có giá trị 1 và GOOD giá trị 0. Đồng thời trong các công thức diễn giải và bảng thống kê, nhãn BAD là positive và GOOD là negative. Positive và Negative ở đây chỉ là qui ước tương ứng với giá trị 1 và 0 chứ không nên hiểu theo nghĩa đen là <code class="highlighter-rouge">tích cực</code> và <code class="highlighter-rouge">tiêu cực</code>.</p>

<p>Một mô hình phân loại $f$ đưa ra kết quả dự báo trên tập train được thống kê trên bảng chéo như sau:</p>

<p><img src="/assets/images/20200813_ModelMetric/pic1.png" class="largepic" /></p>

<p>Các chỉ số TP, FP, TN, FN lần lượt có ý nghĩa là :</p>

<ul>
  <li>TP (True Positive): Tổng số trường hợp dự báo khớp Positive.</li>
  <li>TN (True Negative): Tổng số trường hợp dự báo khớp Negative.</li>
  <li>FP (False Positive): Tổng số trường hợp dự báo các quan sát thuộc nhãn Negative thành Positive.</li>
  <li>FN (False Negative): Tổng số trường hợp dự báo các quan sát thuộc nhãn Positive thành Negative.</li>
</ul>

<p>Những chỉ số trên sẽ là cơ sở để tính toán những metric như accuracy, precision, recall, f1 score mà ta sẽ tìm hiểu bên dưới.
Để tính toán FPR và TPR trên sklearn chúng ta sẽ dựa trên ground truth <code class="highlighter-rouge">y_label</code> và xác suất dự  báo<code class="highlighter-rouge">y_prob</code>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>from sklearn.metrics import roc_curve
# Tính fpr, tpr và threshold 
fpr, tpr, thres = roc_curve(y_label, y_prob, pos_label=1)
# Lưu ý để không nhầm lẫn giữa positive và negative, chúng ta phải định nghĩa nhãn positive thông qua tham số pos_label. Trong TH này thì pos_label = 1
</pre></td></tr></tbody></table></code></pre></div></div>

<h1 id="3-độ-chính-xác-accuracy">3. Độ chính xác (accuracy)</h1>

<p>Khi xây dựng mô hình phân loại chúng ta sẽ muốn biết một cách khái quát tỷ lệ các trường hợp được dự báo đúng trên tổng số các trường hợp là bao nhiêu. Tỷ lệ đó được gọi là độ chính xác. Độ chính xác giúp ta đánh giá hiệu quả dự báo của mô hình trên một bộ dữ liệu. Độ chính xác càng cao thì mô hình của chúng ta càng chuẩn xác. Khi một ai đó nói mô hình của họ dự báo chính xác 95% thì chúng ta hiểu rằng họ đang đề cập tới độ chính xác và được tính toán như sau:</p>

<script type="math/tex; mode=display">\text{Accuracy} = \frac{TP+TN}{\text{total sample}} = \frac{55+850}{1000} = 90.5 \%</script>

<p>Trong các metrics đánh giá mô hình phân loại thì độ chính xác là metric khá được ưa chuộng vì nó có công thức tường minh và dễ diễn giải ý nghĩa. Tuy nhiên hạn chế của nó là đo lường trên <em>tất cả</em> các nhãn mà không quan tâm đến độ chính xác trên từng nhãn. Do đó nó không phù hợp để đánh giá những tác vụ mà <em>tầm quan trọng</em> của việc dự báo các nhãn không còn như nhau. Hay nói cách khác, như trong ví dụ phân loại nợ xấu, việc chúng ta phát hiện đúng một hồ sơ nợ xấu quan trọng hơn việc chúng ta phát hiện đúng một hồ sơ thông thường.</p>

<p>Khi đó chúng ta sẽ quan tâm hơn tới độ chính xác được đo lường chỉ <strong>trên nhãn BAD</strong> hơn và sẽ cần những metrics như precision, recall đánh giá chuyên biệt trên nhóm này. Cùng tìm hiểu về các metrics này bên dưới.</p>

<p>Tính toán accuracy trên sklearn :</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>from sklearn.metrics import accuracy_score
accuracy_score(y_true, y_pred)
</pre></td></tr></tbody></table></code></pre></div></div>
<p>Trong đó y_label là nhãn của dữ liệu và y_pred là nhãn dự báo.</p>
<h1 id="4-precision">4. Precision</h1>

<p>Precision trả lời cho câu hỏi trong các trường hợp được dự báo là positive thì có bao nhiêu trường hợp là đúng ? Và tất nhiên precision càng cao thì mô hình của chúng ta càng tốt trong việc phân loại hồ sơ BAD. Công thức của precision như sau:</p>

<script type="math/tex; mode=display">\text{Precision} = \frac{TP}{\text{total predicted positive}} = \frac{TP}{TP+FP} = \frac{55}{55+50} = 52.4 \%</script>

<p>Precision sẽ cho chúng ta biết mức độ tin cậy mà mô hình đưa ra dự đoán trên hồ sơ BAD. Ví dụ khi precision = 52.4%, chúng ta tin rằng phép đo được tiến hành trên toàn bộ các trường hợp BAD thì xác suất phân loại đúng hồ sơ BAD là 52.4%.</p>

<p>Cũng có ý nghĩa gần tương tự như precision và giúp đo lường hiệu suất dự báo trên positive, đó là recall.</p>

<h1 id="5-recall">5. Recall</h1>

<p>Recall đo lường tỷ lệ dự báo chính xác các trường hợp positive trên toàn bộ các mẫu thuộc nhóm positive. Công thức của recall như sau:</p>

<script type="math/tex; mode=display">\text{Recall} = \frac{TP}{\text{total actual positive}} = \frac{TP}{TP+FN} = \frac{55}{55+45}=55 \%</script>

<p>Recall thường được dùng để đánh gía trên tập train và validation vì chúng ta đã biết trước nhãn. Trên tập test khi dữ liệu được coi như mới hoàn toàn và chưa biết nhãn thì chúng ta sẽ sử dụng precision.</p>

<p>Tính toán precision và recall trên sklearn chúng ta sẽ dựa trên ground truth <code class="highlighter-rouge">y_label</code> và xác suất dự  báo<code class="highlighter-rouge">y_prob</code>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>from sklearn.metrics import precision_recall_curve
prec, rec, thres = precision_recall_curve(y_label, y_prob)
</pre></td></tr></tbody></table></code></pre></div></div>

<h1 id="6-trade-off-giữa-precision-và-recall">6. Trade off giữa precision và recall</h1>

<p>Thông thường các model sẽ lựa chọn một ngưỡng mặc định là 0.5 để quyết định nhãn. Tức là nếu ta có một mô hình phân loại $f_{\theta}()$ thì kết quả nhãn dự báo sẽ dựa trên độ lớn của xác suất dự báo như sau:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
            \left\{
              \begin{array}{l l}
                f_{\theta}(x) \geq 0.5, \text{label} = 1\\
                f_{\theta}(x) < 0.5, \text{label} = 0
              \end{array} \right.
            \end{equation} %]]></script>

<p>Do đó precision và recall sẽ không cố định mà chịu sự biến đổi theo ngưỡng xác suất được lựa chọn. Bên dưới là một đồ thị minh họa cho sự biến đổi này. Đồ thị được trích từ <a href="https://www.kaggle.com/phamdinhkhanh/home-credit-default-risk">home credit kaggle kernel - phamdinhkhanh</a>.</p>

<p><img src="/assets/images/20200813_ModelMetric/pic2.png" class="largepic" /></p>

<p>Thậm chí bằng một chút suy luận logic, ta còn có thể chứng minh được mối quan hệ giữa precision và recall khi biến đổi theo threshold là mối quan hệ đánh đổi (<em>trade off</em>). Khi precision cao thì recall thấp và ngược lại. Thật vậy :</p>

<ul>
  <li>
    <p>Giả sử trong ví dụ về phân loại nợ xấu, chúng ta muốn khi mô hình dự báo một hồ sơ là BAD thật chắc chắn nên lựa chọn một ngưỡng threshold cao hơn, chẳng hạn như 0.9. Khi đó một hồ sơ rơi vào BAD thì khả năng rất rất cao là hồ sơ đó sẽ đúng là BAD bởi xác suất 90% là một mức tin cậy khá cao. Mặt khác xin nhắc lại precision bằng <strong>số lượng được dự báo là BAD đúng</strong> chia cho tổng số <strong>được dự báo là BAD</strong> nên nó có xu hướng cao khi threshold được thiết lập cao. Đồng thời do số lượng các quan sát được dự báo là BAD sẽ giảm xuống khi threshold cao hơn và số lượng hồ sơ BAD không đổi nên recall thấp hơn.</p>
  </li>
  <li>
    <p>Trong trường hợp chúng ta muốn nới lỏng kết quả phân loại hồ sơ BAD một chút bằng cách giảm threshold và chấp nhận một số hợp đồng bị dự báo sai từ GOOD sang BAD. Khi đó số lượng hồ sơ được dự báo là BAD tăng lên trong khi số lượng hồ sơ BAD được dự báo đúng tăng không đáng kể. Điều đó dẫn tới precision giảm và recall tăng.</p>
  </li>
</ul>

<p>Sự đánh đổi giữa precision và recall khiến cho kết quả của mô hình thường dẫn tới precision cao, recall thấp hoặc precision thấp, recall cao. Khi đó rất khó để lựa chọn đâu là một mô hình tốt vì không biết rằng đánh giá trên precision hay recall sẽ phù hợp hơn. Chính vì vậy chúng ta sẽ tìm cách kết hợp cả precision và recall trong một chỉ số mới, đó chính là f1 score.</p>

<h1 id="7-f1-score">7. F1 Score</h1>

<p>$F_1$ Score là trung bình điều hòa giữa precision và recall. Do đó nó đại diện hơn trong việc đánh gía độ chính xác trên đồng thời precision và recall.</p>

<script type="math/tex; mode=display">\text{F}_1 = \frac{2}{\text{precision}^{-1}+\text{recall}^{-1}} = \frac{2}{0.524^{-1} + 0.55^{-1}} = 53.7 \%</script>

<p>Ta chứng minh được rằng giá trị của $F_1$ score luôn nằm trong khoảng của precision và recall. Thật vậy :</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{eqnarray} \text{F}_1 & = & \frac{2~\text{precision}\times\text{recall}}{\text{precision}+\text{recall}} \\
& \leq & \frac{2~\text{precision}\times\text{recall}}{2~\min(\text{precision}, \text{recall})} = \max(\text{precision}, \text{recall})
\end{eqnarray} %]]></script>

<p>Tương tự:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{eqnarray} \text{F}_1 & = & \frac{2~\text{precision}\times\text{recall}}{\text{precision}+\text{recall}} \\
& \geq & \frac{2~\text{precision}\times\text{recall}}{2~\max(\text{precision}, \text{recall})} = \min(\text{precision}, \text{recall})
\end{eqnarray} %]]></script>

<p>Do đó đối với những trường hợp mà precision và recall quá chênh lệch thì $F_1$ score sẽ cân bằng được cả hai độ lớn này và giúp ta đưa ra một đánh giá khách quan hơn. Ví dụ như kết quả bảng bên dưới :</p>

<p><img src="/assets/images/20200813_ModelMetric/pic3.png" class="largepic" /></p>

<p>Nếu dựa trên precision thì giá trị precision=91.6% cho thấy đây là một model <em>khá tốt</em>. Tuy nhiên trong 100 trường hợp positive thì mô hình chỉ nhận diện được đúng 55 trường hợp nên xét theo recall=55% thì đây không phải là một mô hình tốt. Trong trường hợp này $F_1$ sẽ được sử dụng như một chỉ số đại diện cho cả precision và recall. Điểm $F_1$ bằng 69% cho thấy đây là một mô hình có sức mạnh ở mức trung bình và đánh giá của chúng ta sẽ xác thực hơn so với việc quá lạc quan vào mô hình khi chỉ nhìn vào precision và quá bi quan nếu chỉ dựa trên recall.</p>

<p>Trên sklearn, f1 score được tính như sau :</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>from sklearn.metrics import f1_score
f1_score(y_label, y_pred)
</pre></td></tr></tbody></table></code></pre></div></div>
<p>Trong đó y_label là nhãn của dữ liệu và y_pred là nhãn dự báo.</p>

<h1 id="8-tại-sao-f1-score-không-là-trung-bình-cộng-precision-và-recall">8. Tại sao F1 score không là trung bình cộng precision và recall</h1>
<p>Có một học viên thắc mắc mình rằng tại sao $F_1$ score không được lấy bằng trung bình cộng giữa precision và recall? Lấy ví dụ trực quan trong trường hợp mô hình của bạn có precision quá thấp và recall quá cao, chẳng hạn precision=0.01 và recall=1.0.</p>

<p>Nhìn vào biểu đồ trade off giữa precision và recall thì đây có thể được xem như một mô hình thiết lập threshold thấp. 
Nó tương đương với việc dự đoán ngẫu nhiên toàn bộ là positive. Do đó không thể xem đó là một mô hình tốt.</p>

<p>Nếu sử dụng công thức trung bình thì $\text{F}_1 = \frac{\text{precision+recall}}{2} = 0.5005$ cho thấy đây là một mô hình ở mức trung bình. Trong khi sử dụng công thức trung bình điều hòa thì $\text{F}_1 = \frac{2~\text{precision}\times\text{recall}}{\text{precision}+\text{recall}} \approx 0$ và giúp đánh giá được mô hình không tốt.</p>

<p>Tóm lại sử dụng trung bình điều hòa sẽ đánh giá tốt hơn trong trường hợp mô hình có precision cao, recall thấp hoặc precision thấp, recall cao.</p>

<h1 id="9-accuracy-và-f1-score">9. Accuracy và F1 score</h1>

<p>Accuracy và F1 score đều được sử dụng để đánh giá hiệu suất của mô hình trong việc phân loại. Vậy trong tình huống nào chúng ta nên sử dụng chỉ số nào là phù hợp ? Điều đó phụ thuộc vào bộ dữ liệu của bạn có xảy ra hiện tượng mất cân bằng hay không ? Hãy cùng quay trở lại phân tích bảng kết quả đầu tiên :</p>

<p><img src="/assets/images/20200813_ModelMetric/pic4.png" class="largepic" /></p>

<p>Trong trường hợp này ta dễ dàng tính được accuracy=90.5% đây là một kết quả cũng khá cao và chúng ta nhận định rằng mô hình phân loại tốt.</p>

<p>Tuy nhiên xét tình huống chúng ta dự báo toàn bộ mẫu là các hồ sơ GOOD. Như vậy độ chính xác đạt được thậm chí đã lên tới 90%. Lúc này chúng ta nghi ngờ sự phù hợp của accuracy trong việc đánh giá mô hình vì không cần tới mô hình cũng tạo ra một kết quả gần như tương đương với có mô hình.</p>

<p>Khi mất cân bằng dữ liệu, accuracy thường có kết quả cao và dẫn tới quá lạc quan khi đánh giá mô hình. Do đó nó không phù hợp để đánh giá các dữ liệu mất cân bằng. Trong trường hợp dữ liệu mất cân bằng, chúng ta sẽ quan tâm hơn tới độ chính xác trên nhóm thiểu số và $F_1$ score là một chỉ số  đánh giá lý tưởng hơn.</p>

<h1 id="10-auc">10. AUC</h1>

<p>ROC là đường cong biểu diễn khả năng phân loại của một mô hình phân loại tại các ngưỡng threshold. Đường cong này dựa trên hai chỉ số :</p>

<ul>
  <li>TPR (true positive rate): Hay còn gọi là recall hoặc sensitivity. Là tỷ lệ các trường hợp phân loại đúng positive trên tổng số các trường hợp thực tế là positive. Chỉ số này sẽ đánh giá mức độ dự báo chính xác của mô hình trên positive. Khi giá trị của nó càng cao, mô hình dự báo càng tốt <strong>trên nhóm positive</strong>. Nếu $\text{TPR}=0.9$, chúng ta tin rằng 90% các mẫu thuộc nhóm positive đã được mô hình phân loại đúng.</li>
</ul>

<script type="math/tex; mode=display">\text{TPR}\text{/recall}\text{/sensitivity} = \frac{TP}{\text{total positive}}</script>

<ul>
  <li>FPR (false positive rate): Tỷ lệ dự báo sai các trường hợp thực tế là negative thành thành positive trên tổng số các trường hợp thực tế là negative. Nếu giá trị của $\text{FPR}=0.1$, mô hình đã dự báo sai 10% trên tổng số các trường hợp là negative. Một mô hình có FPR càng thấp thì mô hình càng chuẩn xác vì sai số của nó <strong>trên nhóm negative</strong> càng thấp. Phần bù của FPR là specificity đo lường tỷ lệ dự báo đúng các trường hợp negative trên tổng số các trường hợp thực tế là negative.</li>
</ul>

<script type="math/tex; mode=display">\text{FPR} = 1-\text{specificity}= \frac{FP}{\text{total negative}}</script>

<p>Đồ thị ROC là một đường cong cầu lồi dựa trên TPR và FPR có hình dạng như bên dưới:</p>

<p><img src="/assets/images/20200813_ModelMetric/pic5.jpeg" class="largepic" /></p>

<p>AUC là chỉ số được tính toán dựa trên đường cong ROC (receiving operating curve) nhằm <strong>đánh giá khả năng phân loại</strong> của mô hình tốt như thế nào ? Phần diện tích gạch chéo nằm dưới đường cong ROC và trên trục hoành là AUC (area under curve) có giá trị nằm trong khoảng [0, 1]. Khi diện tích này càng lớn thì đường cong ROC có xu hướng tiệm cận đường thẳng $y=1$ và khả năng phân loại của mô hình càng tốt. Khi đường cong ROC nằm sát với đường chéo đi qua hai điểm (0, 0) và (1, 1), mô hình sẽ tương đương với một phân loại ngẫu nhiên.</p>

<p>AUC được tính toán như sau:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>from sklearn.metrics import auc, roc_curve
fpr, tpr, thres = metrics.roc_curve(y_label, y_pred)
# Tính toán auc
auc(fpr, tpr)
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Biểu diễn đường cong ROC:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre>def _plot_roc_curve(fpr, tpr, thres):
    roc = plt.figure(figsize = (10, 8))
    plt.plot(fpr, tpr, 'b-', label = 'ROC')
    plt.plot([0, 1], [0, 1], '--')
    plt.axis([0, 1, 0, 1])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')

_plot_roc_curve(fpr, tpr, thres)
</pre></td></tr></tbody></table></code></pre></div></div>

<h1 id="11-mối-quan-hệ-giữa-tpr-và-fpr">11. Mối quan hệ giữa TPR và FPR</h1>

<p>TPR và FPR sẽ có mối quan hệ cùng chiều. Thật vậy, chúng ta sẽ cùng diễn giải điều này qua hình vẽ bên dưới.</p>

<p><img src="/assets/images/20200813_ModelMetric/pic6.jpeg" class="largepic" /></p>

<p><strong>Hình 1:</strong> Đồ thị phân phối của mật độ xác suất (probability densitiy function - pdf) của điểm số nhóm negative bên trái và nhóm positive bên phải. Mô hình sẽ căn cứ vào đường thẳng threshold vuông góc với trục hoành ($y$) để  đưa ra dự báo là positive hay negative. Nếu điểm số nằm bên trái threshold thì sẽ được dự báo là negative và nằm bên phải được dự báo là positive. Như vậy trên hình vẽ, phần diện tích $FP$ sẽ là false positive rate phần diện tích $TP$ sẽ là true positive rate. Khi ta dịch chuyển ngưỡng threshold từ trái sang phải thì các phần diện tích $FP$ và $TP$ sẽ cùng tăng dần. Điều này tương ứng với mối quan hệ giữa TPR (true positive rate) và FPR (false positive rate) là đồng biến theo sự thay đổi của threshold.</p>

<p>Bây giờ bạn đã hiểu tại sao đường cong ROC lại là một đường đồng biến rồi chứ ?</p>

<p>Ngoài ra mô hình dự báo xác suất của chúng ta sẽ càng tốt nếu đồ thị phân phối xác suất của negative và positive có sự tách biệt càng lớn. Khi đó phần diện tích chồng lấn giữa hai phân phối càng nhỏ và mô hình giảm thiểu tỷ lệ dự báo nhầm. Đồng thời các phân phối xác suất giữa negative và positive càng cách xa nhau thì đồ thị ROC càng lồi. Tính chất lồi của ROC được thể hiện qua độ lớn của phần diện tích AUC.</p>

<h1 id="12-gini-và-cap">12. gini và CAP</h1>

<p>Trong lĩnh vực credit risk, các mô hình scorecard sử dụng hệ số gini làm thước đo đánh giá sức mạnh phân loại của các mô hình. Hệ số này cho thấy khả năng một hồ sơ sẽ vỡ nợ trong tương lai được nhận biết từ mô hình là bao nhiêu phần trăm. Một mô hình scorecard càng mạnh thì hệ số gini càng cao và phân phối điểm số của hai nhóm GOOD và BAD sẽ càng khác biệt. Giá trị của gini nằm giao động trong khoảng [0, 1].</p>

<p>Một hệ số khác tương tự như gini đó là <strong>CAP</strong> (<em>Cumulative Accuracy Profile</em>). Hệ số này được tính toán dựa trên đường cong CAP có biểu diễn như hình bên dưới:</p>

<p><img src="https://4.bp.blogspot.com/-Z91ISbjxfYY/XWmOIgUy8gI/AAAAAAAAIE0/OVN8xgWxlLcyUQKDTp6oeA5NwCz7heKVgCLcBGAs/s1600/accuracy%2Bratio.PNG" class="largepic" /></p>

<p><strong>Hình 2</strong> Hệ số CAP và đường cong CAP của mô hình scorecard. Trên đồ thị, trục hoành biểu diễn tỷ lệ phần trăm tích lũy của số lượng hồ sơ vay và trục tung biểu diễn phần trăm tích lũy của số lượng hồ sơ vay của nhóm BAD được thống kê từ phần trăm mẫu được rút ra tương ứng trên trục hoành. Các hồ sơ sẽ được sắp xếp theo điểm số giảm dần. Đầu tiên chúng ta sẽ lấy ra một tỷ lệ $x$% hồ sơ có điểm số cao nhất tương ứng với điểm $x$ trên trục hoành. Từ mẫu $x$% này, chúng ta thống kê được $y$% tỷ lệ các hồ sơ BAD được phát hiện. Sau đó gia tăng dần kích thước mẫu tích lũy ta sẽ thu được đường CAP như đường <em>curent model</em> trên hình vẽ.</p>

<p>Trên hình vẽ chúng ta có 3 đường cong CAP đó là <em>perfect model, current model, random model</em> lần lượt tương ứng với các model hoàn hảo (<em>perfect model</em>), model hiện tại và model ngẫu nhiên. Model hoàn hảo là mô hình phân loại một cách hoàn hảo các hồ sơ nợ xấu. Đường CAP của mô hình hoàn hảo sẽ tiệm cận với đường thẳng $y=1$ cho thấy rằng chúng ta có thể lựa chọn một ngưỡng điểm nào đó nằm giữa (0, 1) sao cho mô hình phân loại được 100% các trường hợp vỡ nợ. Mô hình hoàn hảo rất ít khi đạt được trên thực tế và nếu có một mô hình gần tiệm cận với đường thẳng $y=1$ thì đó là một mô hình rất rất tốt.</p>

<p>Đối lập với đường CAP hoàn hảo là đường CAP ngẫu nhiên. Đường CAP này biểu diễn kết quả của một sự phân loại ngẫu nhiên các nhãn BAD nên tỷ lệ hồ sơ BAD phân phối đều trên toàn miền điểm số. Do đó hình dạng của đường CAP ngẫu nhiên sẽ tiệm cận với đường chéo chính đi qua (0, 0) và (1, 1).</p>

<p><strong>Tại sao phân phối xác suất tích lũy của BAD lại là một đường cong lồi ?</strong></p>

<ul>
  <li>
    <p>Giả sử chúng ta lựa chọn tập mẫu $S$ gồm $x$% quan sát có điểm <em>cao nhất</em> (lưu ý là các quan sát đã được sắp xếp theo điểm số giảm dần). Do BAD có phân phối chủ yếu tập trung vào nhóm có điểm số cao nên tỷ lệ các hồ sơ được dự báo BAD trên tổng số hồ sơ nhãn BAD trong $S$ sẽ lớn hơn tỷ lệ tích lũy các quan sát $x$%. Tỷ lệ này đồng thời cũng chính là TPR (true positive rate) trên $S$.</p>
  </li>
  <li>
    <p>Ở những $x$% cao thì các quan sát được thêm vào có điểm số nhỏ dần và do đó tốc độ tăng của $TPR$ giảm dần. Do đó đường CAP của mô hình hiện tại có hình dạng là một đường cong lồi.</p>
  </li>
</ul>

<p><strong>Công thức CAP:</strong></p>

<p>Hầu hết các mô hình có hình dạng của đường cong CAP tương tự như đường current model. Tức là nằm giữa đường CAP hoàn hảo và CAP ngẫu nhiên. Một mô hình càng tốt nếu đường CAP của nó càng gần đường hoàn hảo và khi đường CAP càng gần đường ngẫu nhiên thì kết quả dự báo của mô hình càng kém. Chỉ số CAP sẽ được tính toán dựa trên phần diện tích A, B nằm giữa các đường CAP hoàn hảo, hiện tại và ngẫu nhiên như trên hình vẽ theo công thức:</p>

<script type="math/tex; mode=display">\text{CAP}=\frac{A}{A+B}</script>

<p><strong>Visualize đường cong CAP như thế nào ?</strong></p>

<p>Để vẽ đường cong CAP chúng ta lần lượt thực hiện các bước sau:</p>

<ul>
  <li>
    <p>B1: Sắp xếp xác suất vỡ nợ được dự báo theo thứ tự <em>giảm dần</em> và chia nó thành 10 phần (decile) với số lượng quan sát đều nhau. Bạn cũng có thể lựa chọn chia thành 15, 20 phần, tùy theo kích thước tập huấn luyện lớn hay nhỏ. Cách phân chia này sẽ xếp hạng những người vay rủi ro nhất có nhóm xếp hạng (<em>rating grade</em>) thấp nhất và những người vay an toàn nhất nên có nhóm xếp hạng cao nhất.</p>
  </li>
  <li>
    <p>B2: Tính số người vay trong mỗi nhóm (cột <em>number of borrowers</em>).</p>
  </li>
  <li>
    <p>B3: Tính số lượng khách hàng nợ xấu trong mỗi nhóm (cột <em>number of bads</em>).</p>
  </li>
  <li>
    <p>B4: Tính số lượng khách hàng nợ xấu tích lũy trong mỗi nhóm (cột <em>cumulative bads</em>). Nợ xấu tích lũy của một nhóm xếp hạng thứ $i$ sẽ bằng tổng nợ xấu của các nhóm xếp hạng trước đó từ $1,2, \dots$ cho tới $i$.</p>
  </li>
  <li>
    <p>B5: Tính tỷ lệ phần trăm khách hàng nợ xấu trong mỗi nhóm (cột <em>% of bads</em>) có giá trị bằng cột <em>number of bads</em> chia cho tổng số lượng hồ sơ BAD.</p>
  </li>
  <li>
    <p>B6: Tính tỷ lệ phần trăm tích lũy của khách hàng nợ xấu trong mỗi phần (cột <em>cumulative % of bads</em>) được tính dựa trên tổng tích lũy của cột <em>% of bads</em>.</p>
  </li>
</ul>

<p><img src="https://1.bp.blogspot.com/-W1_i0GbUwR0/XWmGot1pJPI/AAAAAAAAIEI/8CbYuNgxBfo1_UTEGT1fleOOO28OxIQ0ACLcBGAs/s1600/CAP%2BCurrent.PNG" class="largepic" /></p>

<p>Khi đó chúng ta sẽ thu được cột cuối cùng tương ứng với giá trị trục tung của đường cong CAP tại các điểm giá trị 10% liên tiếp của trục hoành.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
</pre></td><td class="rouge-code"><pre># 1. Đường cong perfect model
# Số lượng quan sát nhãn positive
no_positive = np.sum(y_train)
# Số lượng quan sát
total = len(y_train)

plt.plot([0, no_positive, total], 
         [0, no_positive, no_positive], 
         c = 'grey', 
         linewidth = 2, 
         label = 'Perfect Model')

# 2. Đường cong ngẫu nhiên 

plt.plot([0, total], 
	 [0, no_positive], 
	 c = 'r', linestyle = '--', label = 'Random Model')

# 3. Đường cong CAP của mô hình hiện tại
# Sắp xếp nhãn y_train theo thứ tự xác suất giảm dần 
y_label_sorted = [y for _, y in sorted(zip(y_prob, y_train))]
# Tổng lũy kế số lượng các quan sát positive theo xác suất giảm dần
y_values = np.append([0], np.cumsum(y_label_sorted))
# Tổng lũy kế số lượng các quan sát
x_values = np.arange(0, total + 1)
# Đường CAP của current model
plt.plot(x_values, 
         y_values, 
         c = 'b',
         label = 'Current CAP model', 
         linewidth = 4)

# Plot information
plt.xlabel('Total observations', fontsize = 16)
plt.ylabel('Positive observations', fontsize = 16)
plt.title('Cumulative Accuracy Profile', fontsize = 16)
plt.legend(loc = 'lower right', fontsize = 16)

</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Đường cong lorenz và hệ số gini</strong></p>

<p>Đường cong lorenz được sử dụng để mô tả sự bất bình đẳng trong phân phối giữa GOOD và BAD. Ý nghĩa của nó tương tự như đường cong CAP. Nhưng chúng ta sẽ thay phân phối tích lũy của số lượng mẫu bằng phân phối tích lũy của GOOD. Đồ thị của đường cong lorenz có hình dạng như bên dưới :</p>

<p><img src="https://3.bp.blogspot.com/-fy7e_Kll_A0/XWxC7yXNe5I/AAAAAAAAIF0/gwrsQHDJRG0DCC26CXLpmcCQbW4Q3Hr3gCLcBGAs/s1600/Gini.PNG" class="largepic" /></p>

<p>Hệ số gini thể hiện mức độ cải thiện của mô hình trong khả năng phân loại GOOD và BAD so với mô hình ngẫu nhiên. Giá trị của hệ số gini được tính bằng diện tích :</p>

<p><script type="math/tex">\text{gini} = \frac{B}{A+B} = 2B</script> do diện tích $A+B = 0.5$</p>

<p><strong>Mối liên hệ giữa gini và AUC</strong></p>

<p>Ngoài ra chúng ta còn có mối liên hệ giữa hệ số gini và AUC theo phương trình sau:</p>

<script type="math/tex; mode=display">\text{gini} = 2\times\text{AUC} - 1</script>

<p><img src="https://4.bp.blogspot.com/-i7SXRA_7SAA/XW9XETnB3OI/AAAAAAAAIIE/gpae-58rUhoJ5RYLD2lv1vPmlBv4rXVkQCLcBGAs/s1600/AUCvsGini.PNG" class="largepic" /></p>

<p>Thật vậy, nếu chúng ta thể hiện trên đồ thị đồng thời đường cong ROC và lorenz thì hai đường này sẽ trùng nhau. Giả sử $A$ là phần diện tích nằm dưới đường thẳng $y=1$ và nằm trên đường cong ROC, $B$ là phần diện tích nằm trên đường chéo chính và dưới đường cong ROC. Khi đó ta sẽ nhận thấy rằng:</p>

<script type="math/tex; mode=display">\text{gini} = 2*B</script>

<script type="math/tex; mode=display">\text{AUC} = B+0.5</script>

<p>Do đó <script type="math/tex">\text{gini} = 2\times \text{AUC}-1</script></p>

<h1 id="13-tổng-kết">13. Tổng kết</h1>

<p>Như vậy qua bài viết này các bạn đã nắm trong tay khá nhiều các chỉ số để đánh giá mô hình phân loại trong machine learning. Đây là những kiến thức cơ bản nhưng lại rất quan trọng mà chúng ta cần phải nắm vững để lựa chọn được mô hình tốt nhất. Đồng thời chúng ta không chỉ biết cách áp dụng mà còn hướng tới hiểu sâu về công thức và ý nghĩa thực tiễn của từng chỉ số.</p>

<p>Để viết được tài liệu này, một phần không thể thiếu là những tài liệu tham khảo bên dưới.</p>

<h1 id="14-tài-liệu-tham-khảo">14. Tài liệu tham khảo</h1>

<ol>
  <li><a href="https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5">Understanding AUC - ROC Curve</a></li>
  <li><a href="https://www.youtube.com/watch?v=W5meQnGACGo">Trade off precision and recall - Andrew Ng</a></li>
  <li><a href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py">Receiver Operating Characteristic (ROC) with cross validation</a></li>
  <li><a href="https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9">Accuracy, Precision, Recall or F1?</a></li>
  <li><a href="https://www.listendata.com/2019/09/gini-cumulative-accuracy-profile-auc.html">gini cumulative accuracy profile auc</a></li>
  <li><a href="https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/">Classification Accuracy is Not Enough: More Performance Measures You Can Use</a></li>
</ol>

<script data-ad-client="ca-pub-4263248182804679" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<button onclick="topFunction()" id="myBtn" title="Go to top">Top</button>

<script src="/js/toc.js"></script>
<script src="/js/btnTop.js"></script>
<script type="text/javascript">
$(document).ready(function() {
    $('#toc').toc();
});
</script>
				</div>
			</div>
			<div class="col-md-2 hidden-xs hidden-sm">
				<a  href="/">
					<img width="100%" style="padding-bottom: 3mm;" src="/assets/images/logo.jpg" /> </a>
				<br>
				<nav>
					<div class="header">Khanh's site</div>
					<li><a style="text-align: left; color: #074B80"  href="https://www.facebook.com/TowardDataScience">phamdinhkhanh blog</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://www.facebook.com/groups/3235479620010379/">phamdinhkhanh AICode forum</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://kaggle.com/phamdinhkhanh">phamdinhkhanh kaggle</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://rpubs.com/phamdinhkhanh">phamdinhkhanh rpub</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://github.com/phamdinhkhanh">phamdinhkhanh github</a></li>
					<br>
					<div class="header">other's site</div>
					<li><a style="text-align: left; color: #074B80"  href="https://www.facebook.com/groups/machinelearningcoban/">machine learning cơ bản facebook</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://forum.machinelearningcoban.com/">machine learning cơ bản forum</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://machinelearningmastery.com">machine learning mastery</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://viblo.asia">viblosia</a></li>
					<br>
					<div class="header">Khóa học</div>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs109/">Xác suất thống kê(Probability): CS109</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs246/">Bigdata: CS246</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://cs231n.stanford.edu/">Computer vision cơ bản: CS231N</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs224n/">Natural Language Processing: CS224N</a></li>
					<li><a style="text-align: left; color: #074B80"  href="http://web.stanford.edu/class/cs224w/">Khoá phân tích mạng lưới (analysis of network): CS224W</a></li>
					<li><a style="text-align: left; color: #074B80"  href="https://web.stanford.edu/class/cs20si/">Khóa học Tensorflow: CS20SI</a></li>
				</nav>
			</div>
		</div>
	</div>
	
</body>
</html>
